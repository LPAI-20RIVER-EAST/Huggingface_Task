{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef69b84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#全局变量\n",
    "hub_token = open('/root/hub_token.txt').read().strip()\n",
    "repo_id = 'lansinuote/nlp.8.generation'\n",
    "push_to_hub = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff223689",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2TokenizerFast(name_or_path='gpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[24717, 649, 3200, 507, 422, 262, 21694, 4991], [3642, 1299, 645, 20868, 837, 691, 2248, 1850, 308, 3775]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "#加载编码器\n",
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "\n",
    "#添加pad\n",
    "#tokenizer.add_special_tokens({'pad_token': '<|endoftext|>'})\n",
    "\n",
    "print(tokenizer)\n",
    "\n",
    "#编码试算\n",
    "tokenizer.batch_encode_plus([\n",
    "    'hide new secretions from the parental units',\n",
    "    'contains no wit , only labored gags'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b499b5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e2803f1c73a4798a9ff4786fb067f5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-38626b27fd3c3e47.arrow and /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-c7f4724d606bfae9.arrow\n",
      "Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-9454b0d197fed5e7.arrow\n",
      "Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-6958bd3ad6d5941e.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-1f42b360a5a1a053.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-c30d784104e55b6b.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-eeb64723393e8ef8.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-7c28727ea8e8b19e.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-ea23f3b4845c990f.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-c55bd9b275a43cc3.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-69853f83df46ec3d.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-e8c2508ae15ca61c.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-fbe193a4a7cce931_00000_of_00004.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-fbe193a4a7cce931_00001_of_00004.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-fbe193a4a7cce931_00002_of_00004.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-fbe193a4a7cce931_00003_of_00004.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-03d7c2d18639a36f_00000_of_00004.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-03d7c2d18639a36f_00001_of_00004.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-03d7c2d18639a36f_00002_of_00004.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-03d7c2d18639a36f_00003_of_00004.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-aca74ade5419face.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-7ba71373fd178881.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-06f5e1cbe8c5517e.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-2d0413709e38aacd.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-54493ec401eaeea8.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-9753890946b1a2af.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-061bfcf64fa77821.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-e10badbdc7153a65.arrow\n",
      "Pushing split train to the Hub.\n",
      "Resuming upload of the dataset shards.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c3a0d885dcf442ba09434457d9a3ccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing split test to the Hub.\n",
      "Resuming upload of the dataset shards.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a578e4a2ab8041f18765be43ead7d0d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration lansinuote--nlp.8.generation-8b7658b3335fddd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset None/None to /root/.cache/huggingface/datasets/lansinuote___parquet/lansinuote--nlp.8.generation-8b7658b3335fddd9/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcb6494f2cf444359150820095e921df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e2d4ced547f42edb14048cc53fffd2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/95.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a79fc9d5dcef41a59073ad0865feff0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/266k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "283c349503574dbd810248b3a31939f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/44863 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/107 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/lansinuote___parquet/lansinuote--nlp.8.generation-8b7658b3335fddd9/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a392ad737dc469983dfc758a5784c15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 44863\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 107\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, concatenate_datasets\n",
    "\n",
    "\n",
    "def get_dataset():\n",
    "    #加载数据\n",
    "    dataset = load_dataset('imdb')\n",
    "\n",
    "    #重新切分数据集\n",
    "    dataset = concatenate_datasets(\n",
    "        [dataset['train'], dataset['test'], dataset['unsupervised']])\n",
    "\n",
    "    dataset = dataset.train_test_split(test_size=0.01, seed=0)\n",
    "\n",
    "    #采样,数据量太大了跑不动\n",
    "    dataset['train'] = dataset['train'].shuffle(0).select(range(80000))\n",
    "    dataset['test'] = dataset['test'].shuffle(0).select(range(200))\n",
    "\n",
    "    #分词\n",
    "    def f(data):\n",
    "        #移除<br/>\n",
    "        for i in range(len(data['text'])):\n",
    "            data['text'][i] = data['text'][i].replace('<br /><br />', ' ')\n",
    "\n",
    "        data = tokenizer.batch_encode_plus(data['text'])\n",
    "\n",
    "        return data\n",
    "\n",
    "    dataset = dataset.map(f,\n",
    "                          batched=True,\n",
    "                          num_proc=4,\n",
    "                          batch_size=1000,\n",
    "                          remove_columns=['text', 'label'])\n",
    "\n",
    "    #过滤掉太短的句子\n",
    "    def f(data):\n",
    "        return [sum(i) >= 25 for i in data['attention_mask']]\n",
    "\n",
    "    dataset = dataset.filter(f, batched=True, num_proc=4, batch_size=1000)\n",
    "\n",
    "    #拼合句子到统一的长度\n",
    "    def f(data):\n",
    "        block_size = 512\n",
    "\n",
    "        #展平数据\n",
    "        input_ids = []\n",
    "        for i in data['input_ids']:\n",
    "            input_ids.extend(i)\n",
    "\n",
    "        #切断数据\n",
    "        data = {'input_ids': [], 'attention_mask': []}\n",
    "        for i in range(len(input_ids) // block_size):\n",
    "            block = input_ids[i * block_size:i * block_size + block_size]\n",
    "            data['input_ids'].append(block)\n",
    "            data['attention_mask'].append([1] * block_size)\n",
    "\n",
    "        #设置labels\n",
    "        data['labels'] = data['input_ids'].copy()\n",
    "\n",
    "        return data\n",
    "\n",
    "    dataset = dataset.map(\n",
    "        f,\n",
    "        batched=True,\n",
    "        batch_size=1000,\n",
    "        num_proc=4,\n",
    "    )\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "if push_to_hub:\n",
    "    dataset = get_dataset()\n",
    "    dataset.push_to_hub(repo_id=repo_id, token=hub_token)\n",
    "\n",
    "#直接使用我处理好的数据集\n",
    "dataset = load_dataset(path=repo_id)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "405095b6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5607,\n",
       " {'input_ids': tensor([[ 1842,   284,   511,  ..., 18974,   286,   262],\n",
       "          [   13,  1375, 11258,  ...,  2223,   318, 39976],\n",
       "          [23304,   393,  1997,  ...,  2222,  3589,   284],\n",
       "          ...,\n",
       "          [14169, 30953,   475,  ...,   284,   651,   262],\n",
       "          [ 2646,    13,  1675,  ..., 19147,    11,   290],\n",
       "          [   30,   383,  3807,  ...,   470,   651,   651]]),\n",
       "  'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          ...,\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1]]),\n",
       "  'labels': tensor([[ 1842,   284,   511,  ..., 18974,   286,   262],\n",
       "          [   13,  1375, 11258,  ...,  2223,   318, 39976],\n",
       "          [23304,   393,  1997,  ...,  2222,  3589,   284],\n",
       "          ...,\n",
       "          [14169, 30953,   475,  ...,   284,   651,   262],\n",
       "          [ 2646,    13,  1675,  ..., 19147,    11,   290],\n",
       "          [   30,   383,  3807,  ...,   470,   651,   651]])})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers.data.data_collator import default_data_collator\n",
    "\n",
    "#数据加载器\n",
    "loader = torch.utils.data.DataLoader(\n",
    "    dataset=dataset['train'],\n",
    "    batch_size=8,\n",
    "    collate_fn=default_data_collator,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "for i, data in enumerate(loader):\n",
    "    break\n",
    "\n",
    "len(loader), data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f53f3c45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16303.7184\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(3.9160), torch.Size([8, 512, 50257]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, GPT2Model, PreTrainedModel, PretrainedConfig\n",
    "\n",
    "#加载模型\n",
    "#model = AutoModelForCausalLM.from_pretrained('gpt2')\n",
    "\n",
    "\n",
    "#定义下游任务模型\n",
    "class Model(PreTrainedModel):\n",
    "    config_class = PretrainedConfig\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.pretrained = GPT2Model.from_pretrained('gpt2')\n",
    "        self.fc = torch.nn.Linear(768, tokenizer.vocab_size, bias=False)\n",
    "\n",
    "        #加载预训练模型的参数\n",
    "        parameters = AutoModelForCausalLM.from_pretrained('gpt2')\n",
    "        self.fc.load_state_dict(parameters.lm_head.state_dict())\n",
    "\n",
    "        self.criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels):\n",
    "        logits = self.pretrained(input_ids=input_ids,\n",
    "                                 attention_mask=attention_mask)\n",
    "        logits = logits.last_hidden_state\n",
    "\n",
    "        logits = self.fc(logits)\n",
    "\n",
    "        shift_logits = logits[:, :-1].flatten(end_dim=1)\n",
    "        shift_labels = labels[:, 1:].flatten()\n",
    "\n",
    "        loss = self.criterion(shift_logits, shift_labels)\n",
    "\n",
    "        return {\n",
    "            'loss': loss,\n",
    "            'logits': logits,\n",
    "        }\n",
    "\n",
    "\n",
    "model = Model(PretrainedConfig())\n",
    "\n",
    "#统计参数量\n",
    "print(sum(i.numel() for i in model.parameters()) / 10000)\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = model(**data)\n",
    "\n",
    "out['loss'], out['logits'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbd9b9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 I love this guy for that dude at times...\"\n",
      "\n",
      "\"What was he doing when you said you'd 'leave'? He's so cool.\"\n",
      "1 I love this book.\n",
      "\n",
      "\n",
      "After an hour I found the book's back-story amusing. It was about an Englishman's journey from a\n",
      "2 I love this game. I'm not complaining because it takes place in a great fantasy world.\" (Sarviv Smith)<|endoftext|>T-Mobile\n",
      "3 I love this.\" You hear me?! How can we be all equal? Because we all see it every day...\n",
      "\n",
      "And you take a step\n",
      "4 I love this game and I am using my keyboard as my desktop controller!\n",
      "\n",
      "Thanks to the other reviewers I have heard so many good words for\n"
     ]
    }
   ],
   "source": [
    "def generate(text):\n",
    "\n",
    "    def generate_loop(data):\n",
    "        with torch.no_grad():\n",
    "            out = model(**data)\n",
    "\n",
    "        #取最后一个字\n",
    "        #[5, b, 50257]\n",
    "        out = out['logits']\n",
    "        #[5, 50257]\n",
    "        out = out[:, -1]\n",
    "\n",
    "        #第50大的值,以此为分界线,小于该值的全部赋值为负无穷\n",
    "        #[5, 50257] -> [5, 50]\n",
    "        topk_value = torch.topk(out, 50).values\n",
    "        #[5, 50] -> [5] -> [5, 1]\n",
    "        topk_value = topk_value[:, -1].unsqueeze(dim=1)\n",
    "\n",
    "        #赋值\n",
    "        #[5, 50257]\n",
    "        out = out.masked_fill(out < topk_value, -float('inf'))\n",
    "\n",
    "        #根据概率采样,无放回,所以不可能重复\n",
    "        #[5, 50257] -> [5, 1]\n",
    "        out = out.softmax(dim=1)\n",
    "        out = out.multinomial(num_samples=1)\n",
    "\n",
    "        data['input_ids'] = torch.cat([data['input_ids'], out], dim=1)\n",
    "        data['attention_mask'] = torch.ones_like(data['input_ids'])\n",
    "        data['labels'] = data['input_ids'].clone()\n",
    "\n",
    "        if data['input_ids'].shape[1] >= 30:\n",
    "            return data\n",
    "\n",
    "        return generate_loop(data)\n",
    "\n",
    "    #重复5遍\n",
    "    data = tokenizer.batch_encode_plus([text] * 5, return_tensors='pt')\n",
    "    data['labels'] = data['input_ids'].clone()\n",
    "\n",
    "    data = generate_loop(data)\n",
    "\n",
    "    for i in range(5):\n",
    "        print(i, tokenizer.decode(data['input_ids'][i]))\n",
    "\n",
    "\n",
    "generate('I love this')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb0e6ed9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/pt39/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4.082333564758301 1.9996433030140896e-05 0.28498043052837574\n",
      "50 3.887619972229004 1.981808453718566e-05 0.3094422700587084\n",
      "100 3.889702081680298 1.9639736044230427e-05 0.31237769080234834\n",
      "150 3.979553461074829 1.9461387551275193e-05 0.30039138943248533\n",
      "200 3.8883557319641113 1.9283039058319958e-05 0.31727005870841485\n",
      "250 3.834787368774414 1.9104690565364724e-05 0.3084637964774951\n",
      "300 3.9670369625091553 1.892634207240949e-05 0.3150684931506849\n",
      "350 3.758570432662964 1.8747993579454255e-05 0.31727005870841485\n",
      "400 4.112035751342773 1.856964508649902e-05 0.2837573385518591\n",
      "450 3.6851837635040283 1.8391296593543786e-05 0.3221624266144814\n",
      "500 3.706080675125122 1.821294810058855e-05 0.31727005870841485\n",
      "550 3.8967978954315186 1.8034599607633317e-05 0.32069471624266144\n",
      "600 3.845363140106201 1.7856251114678083e-05 0.3111545988258317\n",
      "650 3.824476718902588 1.767790262172285e-05 0.31727005870841485\n",
      "700 3.8658738136291504 1.7499554128767614e-05 0.3133561643835616\n",
      "750 3.8619003295898438 1.732120563581238e-05 0.31800391389432486\n",
      "800 3.76538348197937 1.7142857142857142e-05 0.3104207436399217\n",
      "850 3.701509714126587 1.696450864990191e-05 0.32436399217221135\n",
      "900 3.9183616638183594 1.6786160156946676e-05 0.30406066536203524\n",
      "950 3.8986635208129883 1.660781166399144e-05 0.30968688845401177\n",
      "1000 3.799992084503174 1.6429463171036208e-05 0.30259295499021527\n",
      "1050 3.848867177963257 1.6251114678080973e-05 0.3131115459882583\n",
      "1100 3.9064295291900635 1.6072766185125735e-05 0.3104207436399217\n",
      "1150 3.764665126800537 1.5894417692170504e-05 0.30772994129158515\n",
      "1200 3.8725485801696777 1.5716069199215267e-05 0.300146771037182\n",
      "1250 3.9415111541748047 1.5537720706260032e-05 0.30968688845401177\n",
      "1300 3.829141855239868 1.53593722133048e-05 0.31947162426614484\n",
      "1350 3.766231060028076 1.5181023720349563e-05 0.32338551859099807\n",
      "1400 3.5635104179382324 1.500267522739433e-05 0.3292563600782779\n",
      "1450 3.7397804260253906 1.4824326734439096e-05 0.325587084148728\n",
      "1500 3.6501870155334473 1.464597824148386e-05 0.3285225048923679\n",
      "1550 3.6137568950653076 1.4467629748528626e-05 0.3439334637964775\n",
      "1600 3.995084524154663 1.4289281255573391e-05 0.3062622309197652\n",
      "1650 3.6676669120788574 1.4110932762618157e-05 0.3219178082191781\n",
      "1700 3.7927067279815674 1.3932584269662923e-05 0.31971624266144816\n",
      "1750 3.7389183044433594 1.3754235776707688e-05 0.32069471624266144\n",
      "1800 3.754830837249756 1.3575887283752454e-05 0.3148238747553816\n",
      "1850 3.753384590148926 1.339753879079722e-05 0.31727005870841485\n",
      "1900 3.8396637439727783 1.3219190297841983e-05 0.3133561643835616\n",
      "1950 3.9125447273254395 1.304084180488675e-05 0.31629158512720157\n",
      "2000 3.871450424194336 1.2862493311931514e-05 0.3038160469667319\n",
      "2050 3.7126071453094482 1.268414481897628e-05 0.31947162426614484\n",
      "2100 3.6521668434143066 1.2505796326021047e-05 0.31604696673189825\n",
      "2150 3.666334390640259 1.2327447833065811e-05 0.32093933463796476\n",
      "2200 3.7045583724975586 1.2149099340110577e-05 0.3133561643835616\n",
      "2250 3.6455442905426025 1.1970750847155344e-05 0.32974559686888455\n",
      "2300 3.7255401611328125 1.1792402354200108e-05 0.31971624266144816\n",
      "2350 3.7785308361053467 1.1614053861244874e-05 0.3082191780821918\n",
      "2400 3.7511119842529297 1.1435705368289637e-05 0.32338551859099807\n",
      "2450 3.6973884105682373 1.1257356875334405e-05 0.33072407045009783\n",
      "2500 3.764211893081665 1.107900838237917e-05 0.3045499021526419\n",
      "2550 3.736396074295044 1.0900659889423934e-05 0.33463796477495106\n",
      "2600 3.692720890045166 1.0722311396468702e-05 0.31702544031311153\n",
      "2650 3.778352975845337 1.0543962903513467e-05 0.31604696673189825\n",
      "2700 3.817049741744995 1.0365614410558231e-05 0.30895303326810175\n",
      "2750 3.7626774311065674 1.0187265917602998e-05 0.3175146771037182\n",
      "2800 3.818392515182495 1.0008917424647762e-05 0.3231409001956947\n",
      "2850 3.8555409908294678 9.830568931692528e-06 0.3167808219178082\n",
      "2900 3.9218850135803223 9.652220438737293e-06 0.30870841487279843\n",
      "2950 3.8410160541534424 9.473871945782059e-06 0.3202054794520548\n",
      "3000 3.793825387954712 9.295523452826825e-06 0.313600782778865\n",
      "3050 3.848062038421631 9.11717495987159e-06 0.3062622309197652\n",
      "3100 3.613452911376953 8.938826466916356e-06 0.3258317025440313\n",
      "3150 3.8524436950683594 8.760477973961121e-06 0.30528375733855184\n",
      "3200 3.7400779724121094 8.582129481005887e-06 0.3133561643835616\n",
      "3250 3.6905367374420166 8.403780988050651e-06 0.3250978473581213\n",
      "3300 3.731231212615967 8.225432495095416e-06 0.324853228962818\n",
      "3350 3.763906717300415 8.047084002140184e-06 0.3145792563600783\n",
      "3400 3.781609296798706 7.868735509184948e-06 0.31898238747553814\n",
      "3450 3.810610771179199 7.690387016229713e-06 0.3101761252446184\n",
      "3500 3.852665424346924 7.512038523274479e-06 0.312133072407045\n",
      "3550 3.8405373096466064 7.333690030319245e-06 0.3116438356164384\n",
      "3600 3.666443347930908 7.15534153736401e-06 0.3358610567514677\n",
      "3650 3.7960991859436035 6.976993044408776e-06 0.3275440313111546\n",
      "3700 3.743593215942383 6.79864455145354e-06 0.31629158512720157\n",
      "3750 3.7790327072143555 6.620296058498307e-06 0.31066536203522505\n",
      "3800 3.801100969314575 6.4419475655430715e-06 0.31702544031311153\n",
      "3850 3.824488401412964 6.263599072587837e-06 0.3150684931506849\n",
      "3900 3.7158119678497314 6.085250579632602e-06 0.3253424657534247\n",
      "3950 3.8008787631988525 5.906902086677368e-06 0.32240704500978473\n",
      "4000 3.5840561389923096 5.728553593722134e-06 0.33806262230919765\n",
      "4050 3.843273162841797 5.550205100766899e-06 0.3111545988258317\n",
      "4100 3.6767938137054443 5.371856607811664e-06 0.33072407045009783\n",
      "4150 3.8418431282043457 5.193508114856431e-06 0.31262230919765166\n",
      "4200 3.7824509143829346 5.0151596219011954e-06 0.3148238747553816\n",
      "4250 3.8673791885375977 4.836811128945961e-06 0.30577299412915854\n",
      "4300 3.674003839492798 4.658462635990727e-06 0.31702544031311153\n",
      "4350 3.6989810466766357 4.480114143035491e-06 0.3339041095890411\n",
      "4400 3.7002458572387695 4.301765650080257e-06 0.3270547945205479\n",
      "4450 3.616299629211426 4.1234171571250226e-06 0.33170254403131116\n",
      "4500 3.6922073364257812 3.945068664169788e-06 0.3250978473581213\n",
      "4550 3.485079765319824 3.7667201712145533e-06 0.3478473581213307\n",
      "4600 3.72226881980896 3.5883716782593193e-06 0.312133072407045\n",
      "4650 3.885897397994995 3.4100231853040845e-06 0.32069471624266144\n",
      "4700 3.757636308670044 3.23167469234885e-06 0.31702544031311153\n",
      "4750 3.755120038986206 3.0533261993936153e-06 0.32460861056751467\n",
      "4800 3.699784755706787 2.874977706438381e-06 0.32460861056751467\n",
      "4850 3.701230525970459 2.696629213483146e-06 0.3250978473581213\n",
      "4900 3.576190948486328 2.518280720527912e-06 0.3339041095890411\n",
      "4950 3.6719753742218018 2.3399322275726772e-06 0.32265166340508805\n",
      "5000 3.790381669998169 2.1615837346174424e-06 0.311399217221135\n",
      "5050 3.7564635276794434 1.983235241662208e-06 0.33145792563600784\n",
      "5100 3.752413034439087 1.8048867487069736e-06 0.30797455968688847\n",
      "5150 3.7325167655944824 1.626538255751739e-06 0.31531311154598823\n",
      "5200 3.7380337715148926 1.4481897627965043e-06 0.31580234833659493\n",
      "5250 3.691426992416382 1.26984126984127e-06 0.31922700587084146\n",
      "5300 3.710665225982666 1.0914927768860355e-06 0.3131115459882583\n",
      "5350 3.805980920791626 9.131442839308009e-07 0.3150684931506849\n",
      "5400 3.657137155532837 7.347957909755663e-07 0.32632093933463796\n",
      "5450 3.621250629425049 5.564472980203318e-07 0.3292563600782779\n",
      "5500 3.903874158859253 3.780988050650972e-07 0.31262230919765166\n",
      "5550 3.6420700550079346 1.9975031210986268e-07 0.32901174168297453\n",
      "5600 3.79259991645813 2.1401819154628145e-08 0.3253424657534247\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fee6f586e564cbeac8ace4a69e7a0a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/665M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feebd10855d5436089a4c4362bae8e28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "from transformers.optimization import get_scheduler\n",
    "\n",
    "\n",
    "#训练\n",
    "def train():\n",
    "    optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "    scheduler = get_scheduler(name='linear',\n",
    "                              num_warmup_steps=0,\n",
    "                              num_training_steps=len(loader),\n",
    "                              optimizer=optimizer)\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "\n",
    "    for i, data in enumerate(loader):\n",
    "        for k in data.keys():\n",
    "            data[k] = data[k].to(device)\n",
    "        out = model(**data)\n",
    "        loss = out['loss']\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        model.zero_grad()\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            labels = data['labels'][:, 1:]\n",
    "            out = out['logits'].argmax(dim=2)[:, :-1]\n",
    "\n",
    "            accuracy = (labels == out).sum().item() / labels.numel()\n",
    "\n",
    "            lr = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "\n",
    "            print(i, loss.item(), lr, accuracy)\n",
    "\n",
    "    model.to('cpu')\n",
    "\n",
    "\n",
    "if push_to_hub:\n",
    "    train()\n",
    "    model.push_to_hub(repo_id=repo_id, use_auth_token=hub_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53c6a16e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce288dd816a14c17a3331e81baa4db11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/105 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66ed0da144304117be56711eb62f2ac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/665M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 I love this film, its very much the work of John McQuaglish. If this movie had nothing else in it other than what it tells\n",
      "1 I love this movie, I watched many of its adventures, I think it has something to do with who I am, how I treat my people.\n",
      "2 I love this movie even though I haven't seen it many times now. I never thought I'd like this movie so much, but now, it\n",
      "3 I love this show, and I hope others can enjoy it. It is certainly one of my top five favorite sitcoms. I would highly recommend this\n",
      "4 I love this show (especially the last episode). The cast of the show are great - I loved Jessica Biel's performance as Elmer and Matt\n"
     ]
    }
   ],
   "source": [
    "#直接使用我训练好的模型\n",
    "model = Model.from_pretrained(repo_id)\n",
    "\n",
    "generate('I love this')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
