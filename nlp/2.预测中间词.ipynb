{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4409b14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#全局变量\n",
    "hub_token = open('/root/hub_token.txt').read().strip()\n",
    "repo_id = 'lansinuote/nlp.2.predict_middle_word'\n",
    "push_to_hub = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b2e6ab7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobertaTokenizerFast(name_or_path='distilroberta-base', vocab_size=50265, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False)})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[0, 37265, 92, 3556, 2485, 31, 5, 20536, 2833, 2], [0, 10800, 5069, 117, 22094, 2156, 129, 6348, 3995, 821, 8299, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "#加载编码器\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilroberta-base', use_fast=True)\n",
    "\n",
    "print(tokenizer)\n",
    "\n",
    "#编码试算\n",
    "tokenizer.batch_encode_plus([\n",
    "    'hide new secretions from the parental units',\n",
    "    'contains no wit , only labored gags'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69c480e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset glue (/root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66bf2462f1634b9d804215e1900d620c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-40784360ebdc84b7.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-7d3d2f7713a0fe97.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-cfc4ff0ff52a2696.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-3a01012aa4277e00.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-f8c51b7aa5b7bfd0.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-0dff2afa055426ec.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-243c621de5385cc0.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-94b493456b6360b7.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-ad41a221d7f840bb.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-8f39b6e51591579d.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-7b576cd1b66932e5.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-566e7a382dcd3f6b.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-51d792075e7fadea_00000_of_00004.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-51d792075e7fadea_00001_of_00004.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-51d792075e7fadea_00002_of_00004.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-51d792075e7fadea_00003_of_00004.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-ee680e531c310239_00000_of_00004.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-ee680e531c310239_00001_of_00004.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-ee680e531c310239_00002_of_00004.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-ee680e531c310239_00003_of_00004.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-5ac324fdc32e9145_00000_of_00004.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-5ac324fdc32e9145_00001_of_00004.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-5ac324fdc32e9145_00002_of_00004.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-5ac324fdc32e9145_00003_of_00004.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-c81957965dcdffea.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-77735d0c9c3f95a4.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-24d2f9a486008290.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-97f1d8511349cd59.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-adcb376643b0fb5d.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-6a8edaaae758c859.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-a85b7622df54e74e.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-1be5b079ced904e4.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-9902e537bb56c2d0.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-b4a4351865458c4f.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-c277975ba7e03045.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-976a094436bbb896.arrow\n",
      "Pushing split train to the Hub.\n",
      "Resuming upload of the dataset shards.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "602863e0de2247d1af56551e5eeb4590",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing split validation to the Hub.\n",
      "Resuming upload of the dataset shards.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88cbb1f5923e4180ace7b68f15dfec43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing split test to the Hub.\n",
      "Resuming upload of the dataset shards.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5850c2001cd1438694c5f6314edd74a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration lansinuote--nlp.2.predict_middle_word-ac370b90ccc7f67b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset None/None to /root/.cache/huggingface/datasets/lansinuote___parquet/lansinuote--nlp.2.predict_middle_word-ac370b90ccc7f67b/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44a8c43d986347558ac7b8097bef12f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6b6864cbcea42ed9aa7a676e0a73246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/51.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c38e8d2d63bc4f85bf61ebcb4739136f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/25.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "041d6e30f6e24c4885e2ed84b0bc3eb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dea5856d87f45798e48b6f54d79a42d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1776 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/861 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/44279 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/lansinuote___parquet/lansinuote--nlp.2.predict_middle_word-ac370b90ccc7f67b/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29626bd8c10640649d200c91f262b34a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(DatasetDict({\n",
       "     test: Dataset({\n",
       "         features: ['input_ids', 'attention_mask', 'labels'],\n",
       "         num_rows: 1776\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['input_ids', 'attention_mask', 'labels'],\n",
       "         num_rows: 861\n",
       "     })\n",
       "     train: Dataset({\n",
       "         features: ['input_ids', 'attention_mask', 'labels'],\n",
       "         num_rows: 44279\n",
       "     })\n",
       " }),\n",
       " {'input_ids': [0, 37265, 92, 3556, 50264, 31, 5, 20536, 2],\n",
       "  'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  'labels': [-100, -100, -100, -100, 2485, -100, -100, -100, -100]})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "def get_dataset():\n",
    "    #加载数据\n",
    "    dataset = load_dataset(path='glue', name='sst2')\n",
    "\n",
    "    #分词,同时删除多余的字段\n",
    "    def f(data):\n",
    "        return tokenizer.batch_encode_plus(data['sentence'])\n",
    "\n",
    "    dataset = dataset.map(f,\n",
    "                          batched=True,\n",
    "                          batch_size=1000,\n",
    "                          num_proc=4,\n",
    "                          remove_columns=['sentence', 'idx', 'label'])\n",
    "\n",
    "    #过滤掉太短的句子\n",
    "    def f(data):\n",
    "        return [len(i) >= 9 for i in data['input_ids']]\n",
    "\n",
    "    dataset = dataset.filter(f, batched=True, batch_size=1000, num_proc=4)\n",
    "\n",
    "    #截断句子,同时整理成模型需要的格式\n",
    "    def f(data):\n",
    "        b = len(data['input_ids'])\n",
    "        data['labels'] = data['attention_mask'].copy()\n",
    "        for i in range(b):\n",
    "            #裁剪长度到9\n",
    "            data['input_ids'][i] = data['input_ids'][i][:9]\n",
    "            data['attention_mask'][i] = [1] * 9\n",
    "            data['labels'][i] = [-100] * 9\n",
    "\n",
    "            #input_ids最后一位是2\n",
    "            data['input_ids'][i][-1] = 2\n",
    "\n",
    "            #每一句话第4个词为mask\n",
    "            #tokenizer.get_vocab()['<mask>'] -> 50264\n",
    "            data['labels'][i][4] = data['input_ids'][i][4]\n",
    "            data['input_ids'][i][4] = 50264\n",
    "\n",
    "        return data\n",
    "\n",
    "    dataset = dataset.map(f, batched=True, batch_size=1000, num_proc=4)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "if push_to_hub:\n",
    "    dataset = get_dataset()\n",
    "    dataset.push_to_hub(repo_id=repo_id, token=hub_token)\n",
    "\n",
    "#直接使用我处理好的数据集\n",
    "dataset = load_dataset(path=repo_id)\n",
    "\n",
    "dataset, dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca303846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5534,\n",
       " {'input_ids': tensor([[    0,   102, 35063,  2156, 50264,  7953,    12,  4530,     2],\n",
       "          [    0,     6,  1195,    87, 50264,   201,     7, 18651,     2],\n",
       "          [    0, 35685,     4, 28519, 50264,    16, 10686,  1035,     2],\n",
       "          [    0,   428, 29022,  2329, 50264,  2156,     5,   232,     2],\n",
       "          [    0,     6, 42327,   924, 50264,   128,    29,   124,     2],\n",
       "          [    0, 39763,     9,    42, 50264,  6667,    50, 10132,     2],\n",
       "          [    0,   405, 28289, 18711, 50264,   350,   203,    15,     2],\n",
       "          [    0,   627,  5128, 38187, 50264,    16,   295,    75,     2]]),\n",
       "  'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
       "  'labels': tensor([[ -100,  -100,  -100,  -100, 39701,  -100,  -100,  -100,  -100],\n",
       "          [ -100,  -100,  -100,  -100,  6437,  -100,  -100,  -100,  -100],\n",
       "          [ -100,  -100,  -100,  -100, 12801,  -100,  -100,  -100,  -100],\n",
       "          [ -100,  -100,  -100,  -100,  7042,  -100,  -100,  -100,  -100],\n",
       "          [ -100,  -100,  -100,  -100,    37,  -100,  -100,  -100,  -100],\n",
       "          [ -100,  -100,  -100,  -100,    16,  -100,  -100,  -100,  -100],\n",
       "          [ -100,  -100,  -100,  -100,   444,  -100,  -100,  -100,  -100],\n",
       "          [ -100,  -100,  -100,  -100,   260,  -100,  -100,  -100,  -100]])})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers.data.data_collator import default_data_collator\n",
    "\n",
    "#能够实现随机mask的collate_fn\n",
    "#如果要使用这个工具类,在数据预处理时就不需要设置数据中的mask,然后让labels=input_ids.copy即可\n",
    "#from transformers import DataCollatorForLanguageModeling\n",
    "#data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer,mlm_probability=0.1)\n",
    "\n",
    "#数据加载器\n",
    "loader = torch.utils.data.DataLoader(\n",
    "    dataset=dataset['train'],\n",
    "    batch_size=8,\n",
    "    collate_fn=default_data_collator,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "for i, data in enumerate(loader):\n",
    "    break\n",
    "\n",
    "len(loader), data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9488731",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "If you want to use `RobertaLMHeadModel` as a standalone, add `is_decoder=True.`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12136.4313\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(18.7176, grad_fn=<NllLossBackward0>), torch.Size([8, 9, 50265]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, RobertaModel, PreTrainedModel, PretrainedConfig\n",
    "\n",
    "#加载模型\n",
    "#model = AutoModelForCausalLM.from_pretrained('distilroberta-base')\n",
    "\n",
    "\n",
    "#定义下游任务模型\n",
    "class Model(PreTrainedModel):\n",
    "    config_class = PretrainedConfig\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.pretrained = RobertaModel.from_pretrained('distilroberta-base')\n",
    "\n",
    "        decoder = torch.nn.Linear(768, tokenizer.vocab_size)\n",
    "        decoder.bias = torch.nn.Parameter(torch.zeros(tokenizer.vocab_size))\n",
    "\n",
    "        self.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(768, 768),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.LayerNorm(768, eps=1e-5),\n",
    "            decoder,\n",
    "        )\n",
    "\n",
    "        #加载预训练模型的参数\n",
    "        parameters = AutoModelForCausalLM.from_pretrained('distilroberta-base')\n",
    "        self.fc[0].load_state_dict(parameters.lm_head.dense.state_dict())\n",
    "        self.fc[2].load_state_dict(parameters.lm_head.layer_norm.state_dict())\n",
    "        self.fc[3].load_state_dict(parameters.lm_head.decoder.state_dict())\n",
    "\n",
    "        self.criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        logits = self.pretrained(input_ids=input_ids,\n",
    "                                 attention_mask=attention_mask)\n",
    "        logits = logits.last_hidden_state\n",
    "\n",
    "        logits = self.fc(logits)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            shifted_logits = logits[:, :-1].reshape(-1, tokenizer.vocab_size)\n",
    "            shifted_labels = labels[:, 1:].reshape(-1)\n",
    "\n",
    "            loss = self.criterion(shifted_logits, shifted_labels)\n",
    "\n",
    "        return {'loss': loss, 'logits': logits}\n",
    "\n",
    "\n",
    "model = Model(PretrainedConfig())\n",
    "\n",
    "#统计参数量\n",
    "print(sum(i.numel() for i in model.parameters()) / 10000)\n",
    "\n",
    "out = model(**data)\n",
    "\n",
    "out['loss'], out['logits'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c924a315",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor([  475,  4149,  1368, 36114,  3159,    76,  1412,    80])\n",
      "tensor([10146,  1295,  2265, 14598, 28805,  1485, 10899,    80])\n",
      "10\n",
      "tensor([ 543,    9,   10,   10,   12, 1569,  822,  275])\n",
      "tensor([ 2579,     9,    10, 24282,    12,   898,  7122,  3968])\n",
      "20\n",
      "tensor([   47,   963,    16,  1180,    33, 27229,   352,  8444])\n",
      "tensor([   52,  4864,    21,  1180,   240, 38821,   352, 26760])\n",
      "30\n",
      "tensor([  10,   92,   14,  385,   98, 3360,    5,   42])\n",
      "tensor([  10, 6087,   14, 3553,  182, 9001,    5,   42])\n",
      "40\n",
      "tensor([  254, 18408,   350,   254,  3820,     8,  1666,    12])\n",
      "tensor([ 1245,  6434, 15605,  1073, 14439,  2156,   149,    12])\n",
      "50\n",
      "tensor([   11, 35499,    16,   269,   352,     8, 23317, 11235])\n",
      "tensor([  562,  3374,  3374,   269,  2156,  2432, 41406, 11235])\n",
      "0.35049019607843135\n",
      "<s>rambles on<mask> a disj</s>\n",
      " in  getting\n",
      "<s>the film often<mask> a mesmerizing</s>\n",
      " achieves  becomes\n",
      "<s>its underlying mythology<mask> a hodge</s>\n",
      " is  becomes\n",
      "<s>imagine a<mask> bad community theater</s>\n",
      " really  really\n",
      "<s>diverting<mask> ridiculous, head</s>\n",
      "ly ,\n",
      "<s>as weber<mask> weissman</s>\n",
      " and  und\n",
      "<s>offers enough<mask> fun to entertain</s>\n",
      " playful  mindless\n",
      "<s>the director,<mask>ven shain</s>\n",
      " ste  ste\n"
     ]
    }
   ],
   "source": [
    "#测试\n",
    "def test():\n",
    "    model.eval()\n",
    "\n",
    "    loader_test = torch.utils.data.DataLoader(\n",
    "        dataset=dataset['test'],\n",
    "        batch_size=8,\n",
    "        collate_fn=default_data_collator,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(loader_test):\n",
    "        #保存下数据中的label,后面计算正确率要用\n",
    "        label = data['labels'][:, 4].clone()\n",
    "\n",
    "        #从数据中抹除掉label,防止模型作弊\n",
    "        data['labels'] = None\n",
    "\n",
    "        #计算\n",
    "        with torch.no_grad():\n",
    "            out = model(**data)\n",
    "\n",
    "        #[8, 10, 50265] -> [8, 10]\n",
    "        out = out['logits'].argmax(dim=2)[:, 4]\n",
    "\n",
    "        correct += (label == out).sum().item()\n",
    "        total += 8\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(i)\n",
    "            print(label)\n",
    "            print(out)\n",
    "\n",
    "        if i == 50:\n",
    "            break\n",
    "\n",
    "    print(correct / total)\n",
    "\n",
    "    for i in range(8):\n",
    "        print(tokenizer.decode(data['input_ids'][i]))\n",
    "        print(tokenizer.decode(label[i]), tokenizer.decode(out[i]))\n",
    "\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1375fcad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/pt39/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 16.206497192382812 0.25 1.9996385977593064e-05\n",
      "50 5.723601341247559 0.5 1.9815684857246115e-05\n",
      "100 5.552875518798828 0.25 1.963498373689917e-05\n",
      "150 4.01291561126709 0.375 1.9454282616552225e-05\n",
      "200 3.9359703063964844 0.375 1.927358149620528e-05\n",
      "250 3.3738934993743896 0.375 1.909288037585833e-05\n",
      "300 4.1954450607299805 0.5 1.8912179255511386e-05\n",
      "350 2.413621187210083 0.625 1.873147813516444e-05\n",
      "400 4.649163246154785 0.5 1.8550777014817495e-05\n",
      "450 2.281928062438965 0.5 1.8370075894470547e-05\n",
      "500 7.373494625091553 0.0 1.81893747741236e-05\n",
      "550 2.061326026916504 0.625 1.8008673653776656e-05\n",
      "600 2.4588379859924316 0.75 1.7827972533429708e-05\n",
      "650 4.1831464767456055 0.625 1.7647271413082763e-05\n",
      "700 2.7687013149261475 0.375 1.7466570292735818e-05\n",
      "750 3.4589526653289795 0.5 1.728586917238887e-05\n",
      "800 2.0876877307891846 0.5 1.7105168052041924e-05\n",
      "850 4.327033996582031 0.125 1.692446693169498e-05\n",
      "900 2.654650926589966 0.5 1.674376581134803e-05\n",
      "950 1.3270173072814941 0.625 1.6563064691001085e-05\n",
      "1000 1.9248449802398682 0.5 1.638236357065414e-05\n",
      "1050 2.266308546066284 0.5 1.6201662450307194e-05\n",
      "1100 3.5420589447021484 0.5 1.6020961329960246e-05\n",
      "1150 2.1046109199523926 0.375 1.58402602096133e-05\n",
      "1200 1.187718152999878 0.625 1.5659559089266356e-05\n",
      "1250 5.008783340454102 0.5 1.547885796891941e-05\n",
      "1300 3.7132842540740967 0.125 1.5298156848572462e-05\n",
      "1350 3.5521836280822754 0.5 1.5117455728225517e-05\n",
      "1400 0.8691349625587463 0.75 1.493675460787857e-05\n",
      "1450 4.216720104217529 0.375 1.4756053487531623e-05\n",
      "1500 1.6785928010940552 0.625 1.457535236718468e-05\n",
      "1550 3.3582770824432373 0.375 1.4394651246837732e-05\n",
      "1600 3.744565010070801 0.125 1.4213950126490786e-05\n",
      "1650 2.163055896759033 0.625 1.4033249006143839e-05\n",
      "1700 1.9629257917404175 0.625 1.3852547885796892e-05\n",
      "1750 2.511786699295044 0.375 1.3671846765449948e-05\n",
      "1800 4.0732855796813965 0.375 1.3491145645103002e-05\n",
      "1850 3.503495216369629 0.5 1.3310444524756055e-05\n",
      "1900 5.063573837280273 0.125 1.3129743404409108e-05\n",
      "1950 2.942742347717285 0.5 1.2949042284062163e-05\n",
      "2000 4.405852794647217 0.375 1.2768341163715217e-05\n",
      "2050 3.71248197555542 0.375 1.258764004336827e-05\n",
      "2100 4.612397193908691 0.375 1.2406938923021324e-05\n",
      "2150 3.6942319869995117 0.375 1.2226237802674377e-05\n",
      "2200 2.602166175842285 0.375 1.2045536682327432e-05\n",
      "2250 1.8951139450073242 0.5 1.1864835561980486e-05\n",
      "2300 2.5316896438598633 0.25 1.168413444163354e-05\n",
      "2350 4.479519844055176 0.5 1.1503433321286593e-05\n",
      "2400 4.103273391723633 0.25 1.1322732200939646e-05\n",
      "2450 1.5231428146362305 0.625 1.11420310805927e-05\n",
      "2500 1.3973701000213623 0.875 1.0961329960245755e-05\n",
      "2550 3.2860970497131348 0.5 1.0780628839898809e-05\n",
      "2600 1.3479187488555908 0.5 1.0599927719551862e-05\n",
      "2650 2.752333641052246 0.375 1.0419226599204916e-05\n",
      "2700 2.584421157836914 0.5 1.023852547885797e-05\n",
      "2750 2.718874931335449 0.25 1.0057824358511023e-05\n",
      "2800 2.302196979522705 0.5 9.877123238164078e-06\n",
      "2850 2.063772201538086 0.25 9.69642211781713e-06\n",
      "2900 3.190934181213379 0.5 9.515720997470185e-06\n",
      "2950 1.9355075359344482 0.5 9.335019877123239e-06\n",
      "3000 3.765559196472168 0.25 9.154318756776292e-06\n",
      "3050 2.715607166290283 0.625 8.973617636429347e-06\n",
      "3100 1.152201533317566 0.75 8.7929165160824e-06\n",
      "3150 4.141539573669434 0.125 8.612215395735455e-06\n",
      "3200 2.3657078742980957 0.5 8.431514275388508e-06\n",
      "3250 1.2509515285491943 0.75 8.25081315504156e-06\n",
      "3300 3.3407325744628906 0.375 8.070112034694616e-06\n",
      "3350 1.7235753536224365 0.75 7.889410914347669e-06\n",
      "3400 2.657092809677124 0.5 7.708709794000724e-06\n",
      "3450 3.1897988319396973 0.5 7.5280086736537775e-06\n",
      "3500 2.2201759815216064 0.375 7.3473075533068315e-06\n",
      "3550 3.0978193283081055 0.5 7.166606432959885e-06\n",
      "3600 3.285536527633667 0.5 6.9859053126129386e-06\n",
      "3650 2.6169135570526123 0.5 6.8052041922659925e-06\n",
      "3700 2.2782294750213623 0.875 6.6245030719190465e-06\n",
      "3750 2.7158079147338867 0.25 6.4438019515721005e-06\n",
      "3800 1.6083488464355469 0.5 6.263100831225154e-06\n",
      "3850 2.432509422302246 0.5 6.082399710878208e-06\n",
      "3900 2.5611073970794678 0.375 5.9016985905312615e-06\n",
      "3950 2.760842800140381 0.5 5.7209974701843155e-06\n",
      "4000 1.395445704460144 0.75 5.5402963498373695e-06\n",
      "4050 1.6985840797424316 0.625 5.359595229490423e-06\n",
      "4100 3.659759044647217 0.5 5.1788941091434774e-06\n",
      "4150 2.181492328643799 0.5 4.9981929887965306e-06\n",
      "4200 1.7814452648162842 0.5 4.8174918684495845e-06\n",
      "4250 2.177046775817871 0.5 4.6367907481026385e-06\n",
      "4300 2.2039895057678223 0.5 4.4560896277556925e-06\n",
      "4350 2.8487253189086914 0.5 4.2753885074087464e-06\n",
      "4400 3.4319212436676025 0.5 4.0946873870618e-06\n",
      "4450 3.533578872680664 0.5 3.9139862667148535e-06\n",
      "4500 0.49483928084373474 0.625 3.7332851463679075e-06\n",
      "4550 2.4885621070861816 0.625 3.5525840260209615e-06\n",
      "4600 2.7385079860687256 0.5 3.3718829056740154e-06\n",
      "4650 2.0667479038238525 0.625 3.1911817853270694e-06\n",
      "4700 3.1814680099487305 0.375 3.0104806649801234e-06\n",
      "4750 1.2146410942077637 0.625 2.8297795446331774e-06\n",
      "4800 2.531301259994507 0.5 2.6490784242862305e-06\n",
      "4850 5.057806015014648 0.25 2.468377303939285e-06\n",
      "4900 2.7309987545013428 0.5 2.2876761835923384e-06\n",
      "4950 2.1304845809936523 0.5 2.1069750632453924e-06\n",
      "5000 3.538896322250366 0.5 1.926273942898446e-06\n",
      "5050 3.0901527404785156 0.5 1.7455728225515001e-06\n",
      "5100 2.140812635421753 0.375 1.5648717022045537e-06\n",
      "5150 4.388651371002197 0.125 1.3841705818576077e-06\n",
      "5200 1.819676399230957 0.5 1.2034694615106614e-06\n",
      "5250 3.1711606979370117 0.375 1.0227683411637154e-06\n",
      "5300 3.9652976989746094 0.25 8.420672208167693e-07\n",
      "5350 2.7989249229431152 0.5 6.61366100469823e-07\n",
      "5400 1.6225651502609253 0.625 4.806649801228768e-07\n",
      "5450 3.159360408782959 0.5 2.9996385977593064e-07\n",
      "5500 3.180147171020508 0.375 1.1926273942898448e-07\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18e43a7980974359b84bb44df8103812",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9163ad7151c0427ba8fbbc3ad128d745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/485M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "from transformers.optimization import get_scheduler\n",
    "\n",
    "\n",
    "#训练\n",
    "def train():\n",
    "    optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "    scheduler = get_scheduler(name='linear',\n",
    "                              num_warmup_steps=0,\n",
    "                              num_training_steps=len(loader),\n",
    "                              optimizer=optimizer)\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    for i, data in enumerate(loader):\n",
    "        for k in data.keys():\n",
    "            data[k] = data[k].to(device)\n",
    "        out = model(**data)\n",
    "        loss = out['loss']\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        model.zero_grad()\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            label = data['labels'][:, 4]\n",
    "            out = out['logits'].argmax(dim=2)[:, 4]\n",
    "\n",
    "            correct = (label == out).sum().item()\n",
    "            accuracy = correct / 8\n",
    "\n",
    "            lr = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "\n",
    "            print(i, loss.item(), accuracy, lr)\n",
    "\n",
    "    model.to('cpu')\n",
    "\n",
    "\n",
    "if push_to_hub:\n",
    "    train()\n",
    "    model.push_to_hub(repo_id=repo_id, use_auth_token=hub_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed397281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "724c31e2c1114a8fab220d1194e55f4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/485M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "If you want to use `RobertaLMHeadModel` as a standalone, add `is_decoder=True.`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor([11290,    29,  3251,     9,  5730,  2230,  3360,  2614])\n",
      "tensor([ 5073,    29,  1569,     9, 12801, 44009,   822,  1478])\n",
      "10\n",
      "tensor([ 3599,    10,    84, 14207,    10, 36396, 34501,   473])\n",
      "tensor([ 4780,    10,    84,  2316,    10,  1569, 16887,   473])\n",
      "20\n",
      "tensor([14838,  5494, 10295,  1344,   563,  1144,   213,   144])\n",
      "tensor([ 6269,  5494, 31790,  1344,   631,  1403,   213,   144])\n",
      "30\n",
      "tensor([  492,    34,     7,  4839, 20030,  2156,  2019,  8396])\n",
      "tensor([  492, 15033,     7,    16,  5282,  2156,  6990,  8396])\n",
      "40\n",
      "tensor([ 2156,   475,  2801,    10,  5906, 39913,   631,   224])\n",
      "tensor([ 2156, 15549,  1581,    10, 34029, 13938,   631, 34600])\n",
      "50\n",
      "tensor([  14,   28,    5,  740, 1473, 2084,   16,   75])\n",
      "tensor([   45,    28,    39,  9931, 29941,  2084,    16,   269])\n",
      "0.5122549019607843\n",
      "<s>the truth is<mask> the truth about</s>\n",
      " that  not\n",
      "<s>audiences can<mask> expected to suspend</s>\n",
      " be  be\n",
      "<s>foster nails<mask> role, giving</s>\n",
      " the  his\n",
      "<s>the use of<mask>gi and digital</s>\n",
      " c  mag\n",
      "<s>for all its<mask> sense of purpose</s>\n",
      " serious  undeniable\n",
      "<s>thurman and<mask>wis are</s>\n",
      " le  le\n",
      "<s>its underlying mythology<mask> a hodge</s>\n",
      " is  is\n",
      "<s>i did n<mask> believe for a</s>\n",
      "'t  really\n"
     ]
    }
   ],
   "source": [
    "#直接使用我训练好的模型\n",
    "model = Model.from_pretrained(repo_id)\n",
    "\n",
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
