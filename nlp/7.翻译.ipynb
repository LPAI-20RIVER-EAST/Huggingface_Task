{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "175d98b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#全局变量\n",
    "hub_token = open('/root/hub_token.txt').read().strip()\n",
    "repo_id = 'lansinuote/nlp.7.translation'\n",
    "push_to_hub = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b2e6ab7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MarianTokenizer(name_or_path='Helsinki-NLP/opus-mt-en-ro', vocab_size=59543, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>'})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/pt39/lib/python3.9/site-packages/transformers/models/marian/tokenization_marian.py:194: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[125, 778, 3, 63, 141, 9191, 23, 187, 32, 716, 9191, 2, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "#加载编码器\n",
    "tokenizer = AutoTokenizer.from_pretrained('Helsinki-NLP/opus-mt-en-ro',\n",
    "                                          use_fast=True)\n",
    "\n",
    "print(tokenizer)\n",
    "\n",
    "#编码试算\n",
    "tokenizer.batch_encode_plus(\n",
    "    [['Hello, this one sentence!', 'This is another sentence.']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69c480e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset wmt16 (/root/.cache/huggingface/datasets/wmt16/ro-en/1.0.0/746749a11d25c02058042da7502d973ff410e73457f3d305fc1177dc0e8c4227)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9932fc2f0e1f4719b9ebe2390aae225d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/wmt16/ro-en/1.0.0/746749a11d25c02058042da7502d973ff410e73457f3d305fc1177dc0e8c4227/cache-e153bf661ff30a9d.arrow\n",
      "Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/wmt16/ro-en/1.0.0/746749a11d25c02058042da7502d973ff410e73457f3d305fc1177dc0e8c4227/cache-04de8b997cf89dc0.arrow\n",
      "Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/wmt16/ro-en/1.0.0/746749a11d25c02058042da7502d973ff410e73457f3d305fc1177dc0e8c4227/cache-d85cda4b0f38d63d.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/wmt16/ro-en/1.0.0/746749a11d25c02058042da7502d973ff410e73457f3d305fc1177dc0e8c4227/cache-eac92af555fe1778.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/wmt16/ro-en/1.0.0/746749a11d25c02058042da7502d973ff410e73457f3d305fc1177dc0e8c4227/cache-6dc27e6d44541abb.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/wmt16/ro-en/1.0.0/746749a11d25c02058042da7502d973ff410e73457f3d305fc1177dc0e8c4227/cache-149277764173b741.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/wmt16/ro-en/1.0.0/746749a11d25c02058042da7502d973ff410e73457f3d305fc1177dc0e8c4227/cache-b9361274081abe39.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/wmt16/ro-en/1.0.0/746749a11d25c02058042da7502d973ff410e73457f3d305fc1177dc0e8c4227/cache-ab32c4661007c50a.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/wmt16/ro-en/1.0.0/746749a11d25c02058042da7502d973ff410e73457f3d305fc1177dc0e8c4227/cache-41717b778c569610.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/wmt16/ro-en/1.0.0/746749a11d25c02058042da7502d973ff410e73457f3d305fc1177dc0e8c4227/cache-98dc5be658a8c705.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/wmt16/ro-en/1.0.0/746749a11d25c02058042da7502d973ff410e73457f3d305fc1177dc0e8c4227/cache-7b3c2913ad26c529.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/wmt16/ro-en/1.0.0/746749a11d25c02058042da7502d973ff410e73457f3d305fc1177dc0e8c4227/cache-6ee305e524c9634d.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/wmt16/ro-en/1.0.0/746749a11d25c02058042da7502d973ff410e73457f3d305fc1177dc0e8c4227/cache-1fc207dafc588430.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/wmt16/ro-en/1.0.0/746749a11d25c02058042da7502d973ff410e73457f3d305fc1177dc0e8c4227/cache-9332ebe962b2e78b.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/wmt16/ro-en/1.0.0/746749a11d25c02058042da7502d973ff410e73457f3d305fc1177dc0e8c4227/cache-568c51836bb49cf3.arrow\n",
      "Pushing split train to the Hub.\n",
      "Resuming upload of the dataset shards.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95db58d8f39443cf851cb4148ca83955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing split validation to the Hub.\n",
      "Resuming upload of the dataset shards.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b1b6bbfced44fb8b42de6a5223f353a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing split test to the Hub.\n",
      "Resuming upload of the dataset shards.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d819f202f2df4547bafb82aa20362a70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration lansinuote--nlp.7.translation-9ebe5b45a0781875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset None/None to /root/.cache/huggingface/datasets/lansinuote___parquet/lansinuote--nlp.7.translation-9ebe5b45a0781875/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "426c1f579ee141db8bd1bfcd15b9d729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a868adcd37ad49f7b1a4c4a8733b111e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/40.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5fcebfb8e5a423ea730d1f3cdd91b42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/40.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25c174a91f1a41a88eb5f97bffa08f68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/3.14M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83c77834db134118bd7baef8db555ab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/lansinuote___parquet/lansinuote--nlp.7.translation-9ebe5b45a0781875/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad1dbbcd935a4e709ebd93b1377a9335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    validation: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 200\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 200\n",
      "    })\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 20000\n",
      "    })\n",
      "}) {'input_ids': [460, 354, 3794, 12, 10677, 20, 5046, 14, 4, 2546, 37, 8, 397, 5551, 30, 10113, 37, 3501, 19814, 18, 8465, 20, 4, 44690, 782, 2, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [902, 576, 2946, 76, 10815, 17, 5098, 14997, 5, 559, 1140, 43, 2434, 6624, 27, 50, 337, 19216, 46, 22174, 17, 2317, 121, 16825, 2, 0]}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "def get_dataset():\n",
    "    #加载数据\n",
    "    dataset = load_dataset(path='wmt16', name='ro-en')\n",
    "\n",
    "    #采样,数据量太大了跑不动\n",
    "    dataset['train'] = dataset['train'].shuffle(1).select(range(20000))\n",
    "    dataset['validation'] = dataset['validation'].shuffle(1).select(range(200))\n",
    "    dataset['test'] = dataset['test'].shuffle(1).select(range(200))\n",
    "\n",
    "    #数据预处理\n",
    "    def preprocess_function(data):\n",
    "        #取出数据中的en和ro\n",
    "        en = [ex['en'] for ex in data['translation']]\n",
    "        ro = [ex['ro'] for ex in data['translation']]\n",
    "\n",
    "        #源语言直接编码就行了\n",
    "        data = tokenizer.batch_encode_plus(en, max_length=128, truncation=True)\n",
    "\n",
    "        #目标语言在特殊模块中编码\n",
    "        with tokenizer.as_target_tokenizer():\n",
    "            data['labels'] = tokenizer.batch_encode_plus(\n",
    "                ro, max_length=128, truncation=True)['input_ids']\n",
    "\n",
    "        return data\n",
    "\n",
    "    dataset = dataset.map(function=preprocess_function,\n",
    "                          batched=True,\n",
    "                          batch_size=1000,\n",
    "                          num_proc=4,\n",
    "                          remove_columns=['translation'])\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "if push_to_hub:\n",
    "    dataset = get_dataset()\n",
    "    dataset.push_to_hub(repo_id=repo_id, token=hub_token)\n",
    "\n",
    "#直接使用我处理好的数据集\n",
    "dataset = load_dataset(path=repo_id)\n",
    "\n",
    "print(dataset, dataset['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c1f61fb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[59542, 10455,   120,    80],\n",
       "        [59542,   301,    53,  4074]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#这个函数和下面这个工具类等价,但我也是模仿实现的,不确定有没有出入\n",
    "#from transformers import DataCollatorForSeq2Seq\n",
    "#DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "#数据批处理函数\n",
    "def collate_fn(data):\n",
    "    #求最长的label\n",
    "    max_length = max([len(i['labels']) for i in data])\n",
    "\n",
    "    #把所有的label都补pad到最长\n",
    "    for i in data:\n",
    "        pads = [-100] * (max_length - len(i['labels']))\n",
    "        i['labels'] = i['labels'] + pads\n",
    "\n",
    "    #把多个数据整合成一个tensor\n",
    "    data = tokenizer.pad(\n",
    "        encoded_inputs=data,\n",
    "        padding=True,\n",
    "        max_length=None,\n",
    "        pad_to_multiple_of=None,\n",
    "        return_tensors='pt',\n",
    "    )\n",
    "\n",
    "    #定义decoder_input_ids\n",
    "    data['decoder_input_ids'] = torch.full_like(data['labels'],\n",
    "                                                tokenizer.get_vocab()['<pad>'],\n",
    "                                                dtype=torch.long)\n",
    "    data['decoder_input_ids'][:, 1:] = data['labels'][:, :-1]\n",
    "    data['decoder_input_ids'][data['decoder_input_ids'] ==\n",
    "                              -100] = tokenizer.get_vocab()['<pad>']\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "data = [{\n",
    "    'input_ids': [21603, 10, 37, 3719, 13],\n",
    "    'attention_mask': [1, 1, 1, 1, 1],\n",
    "    'labels': [10455, 120, 80]\n",
    "}, {\n",
    "    'input_ids': [21603, 10, 7086, 8408, 563],\n",
    "    'attention_mask': [1, 1, 1, 1, 1],\n",
    "    'labels': [301, 53, 4074, 1669]\n",
    "}]\n",
    "\n",
    "collate_fn(data)['decoder_input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ad1647a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids torch.Size([8, 38]) tensor([[   68,   346,    32,  1305,    13,   408,    45,  4682,  8355, 21463,\n",
      "           101,  2868,  5941,     4,   530,   143,   246,     2,     0, 59542,\n",
      "         59542, 59542, 59542, 59542, 59542, 59542, 59542, 59542, 59542, 59542,\n",
      "         59542, 59542, 59542, 59542, 59542, 59542, 59542, 59542],\n",
      "        [  115,    64, 10096,  2649,   131,     4,  1824, 36635,    20, 22789,\n",
      "           433,     4, 24505,     2,     0, 59542, 59542, 59542, 59542, 59542,\n",
      "         59542, 59542, 59542, 59542, 59542, 59542, 59542, 59542, 59542, 59542,\n",
      "         59542, 59542, 59542, 59542, 59542, 59542, 59542, 59542]])\n",
      "attention_mask torch.Size([8, 38]) tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "labels torch.Size([8, 45]) tensor([[  694,    55,  9685,    19, 20596, 17061,  4682,    43, 12434,    19,\n",
      "           227,  7358,  6531,  3835,  1649,     2,     0,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [  119,  1734,  7772,   255,  6291, 21634,    17, 22789,   563,     5,\n",
      "         20326,     2,     0,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100]])\n",
      "decoder_input_ids torch.Size([8, 45]) tensor([[59542,   694,    55,  9685,    19, 20596, 17061,  4682,    43, 12434,\n",
      "            19,   227,  7358,  6531,  3835,  1649,     2,     0, 59542, 59542,\n",
      "         59542, 59542, 59542, 59542, 59542, 59542, 59542, 59542, 59542, 59542,\n",
      "         59542, 59542, 59542, 59542, 59542, 59542, 59542, 59542, 59542, 59542,\n",
      "         59542, 59542, 59542, 59542, 59542],\n",
      "        [59542,   119,  1734,  7772,   255,  6291, 21634,    17, 22789,   563,\n",
      "             5, 20326,     2,     0, 59542, 59542, 59542, 59542, 59542, 59542,\n",
      "         59542, 59542, 59542, 59542, 59542, 59542, 59542, 59542, 59542, 59542,\n",
      "         59542, 59542, 59542, 59542, 59542, 59542, 59542, 59542, 59542, 59542,\n",
      "         59542, 59542, 59542, 59542, 59542]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2500"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "#数据加载器\n",
    "loader = torch.utils.data.DataLoader(\n",
    "    dataset=dataset['train'],\n",
    "    batch_size=8,\n",
    "    collate_fn=collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "for i, data in enumerate(loader):\n",
    "    break\n",
    "\n",
    "for k, v in data.items():\n",
    "    print(k, v.shape, v[:2])\n",
    "\n",
    "len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9488731",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Helsinki-NLP/opus-mt-en-ro were not used when initializing MarianModel: ['final_logits_bias']\n",
      "- This IS expected if you are initializing MarianModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MarianModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10563.4816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(1.3505, grad_fn=<NllLossBackward0>), torch.Size([8, 45, 59543]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, MarianModel, PreTrainedModel, PretrainedConfig\n",
    "\n",
    "#加载模型\n",
    "#model = AutoModelForSeq2SeqLM.from_pretrained('Helsinki-NLP/opus-mt-en-ro')\n",
    "\n",
    "\n",
    "#定义下游任务模型\n",
    "class Model(PreTrainedModel):\n",
    "    config_class = PretrainedConfig\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.pretrained = MarianModel.from_pretrained(\n",
    "            'Helsinki-NLP/opus-mt-en-ro')\n",
    "\n",
    "        self.register_buffer('final_logits_bias',\n",
    "                             torch.zeros(1, tokenizer.vocab_size))\n",
    "\n",
    "        self.fc = torch.nn.Linear(512, tokenizer.vocab_size, bias=False)\n",
    "\n",
    "        #加载预训练模型的参数\n",
    "        parameters = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "            'Helsinki-NLP/opus-mt-en-ro')\n",
    "        self.fc.load_state_dict(parameters.lm_head.state_dict())\n",
    "\n",
    "        self.criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels, decoder_input_ids):\n",
    "        logits = self.pretrained(input_ids=input_ids,\n",
    "                                 attention_mask=attention_mask,\n",
    "                                 decoder_input_ids=decoder_input_ids)\n",
    "        logits = logits.last_hidden_state\n",
    "\n",
    "        logits = self.fc(logits) + self.final_logits_bias\n",
    "\n",
    "        loss = self.criterion(logits.flatten(end_dim=1), labels.flatten())\n",
    "\n",
    "        return {'loss': loss, 'logits': logits}\n",
    "\n",
    "\n",
    "model = Model(PretrainedConfig())\n",
    "\n",
    "#统计参数量\n",
    "print(sum(i.numel() for i in model.parameters()) / 10000)\n",
    "\n",
    "out = model(**data)\n",
    "\n",
    "out['loss'], out['logits'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78f3263f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26234/1560569803.py:4: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(path='sacrebleu')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.0,\n",
       " 'counts': [4, 2, 0, 0],\n",
       " 'totals': [4, 2, 0, 0],\n",
       " 'precisions': [100.0, 100.0, 0.0, 0.0],\n",
       " 'bp': 1.0,\n",
       " 'sys_len': 4,\n",
       " 'ref_len': 4}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "#加载评价函数\n",
    "metric = load_metric(path='sacrebleu')\n",
    "\n",
    "#试算\n",
    "metric.compute(predictions=['hello there', 'general kenobi'],\n",
    "               references=[['hello there'], ['general kenobi']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c924a315",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "input_ids= You are a▁great▁power▁only▁if you▁have▁solutions.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "pred= Eşt tu o, doar daca ai solu soluțiitii.</s>,,,,,-- - - - Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu\n",
      "label= <pad> Dar esti mare putere doar daca ai și solutii.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "2\n",
      "input_ids= I▁can▁guarantee▁we▁haven't▁changed▁nothing▁all▁year with▁our▁defensive▁systems or▁techniques,▁it's▁just that the▁last▁six▁weeks▁we▁have▁made a real▁emphasis with▁our contact in▁tackles and that▁has▁been the turn▁around for us.</s>\n",
      "pred= Pot garanta că n am schimbat nimic tot anul cu sistemele noastre tehnicile noastre defensive, doara timp că ultimele ultimele şase săptămâni am pus un pe-adevăr pe contactele abordai, asta ne fost lucrurile noastră</s>\n",
      "label= <pad> Pot garanta că nu am schimbat nimic tot anul în sistemele sau tehnicile noastre defensive, atâta doar că în ultimele șase săptămâni am pus accentul într-adevăr pe contact în placări și astfel am schimbat situația.\n",
      "4\n",
      "input_ids= In▁Italy, Salvatore and▁his▁wife▁explained to the▁girl▁about her▁origins and that her past▁links her to▁Romania.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "pred= În Italia, Salvae și soția sa-au explicat fetei despre origini provine, că trecutul ei o leagă de România.</s>,ulul Ea În În În În În În În În În În În În În În În În În În În În În În În În În În În În În În În În În În În În În În În În În În În În În În În În\n",
      "label= <pad> În Italia, Salvadore și soția i-au explicat fetei de unde vine și că trecutul ei o leagă de România.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "6\n",
      "input_ids= ▁Few▁give▁Jeremy Corbyn a real▁chance to▁ever▁become prime minister.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "pred= Puţințini dau dau lui reale lui Jeremy Corbyn să devină vreodată prim-.</s>,, Jer Jer Jer Jer Jer Jer Jer Jer Jer Jer Jer Jer Puţin Puţin Puţin Puţin Puţin Puţin Puţin Puţin Puţin Puţin\n",
      "label= <pad> Puțini îi dau șanse reale lui Jeremy Corbyn să ajungă vreodată prim ministru.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "8\n",
      "input_ids= An editorial in the Lancet medical▁journal▁last▁month▁attacked the \"extraordinarily▁flimsy▁foundation\" on▁which PHE▁based▁its▁main▁conclusion.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "pred= Un editorial din luna trecută în revista medicală Lancet a atacat \",F extrem de subţireă pe, care PH-a bazat PHE concluzia principală.</s> DE Edi Edi La La = = = = = = = = = = Un Un Un Un Un Un Un Un Un Un Un Un Un Un Un Un\n",
      "label= <pad> Un articol publicat luna trecută în revista medicală Lancet a atacat <unk> baza extraordinar de fragilă<unk> pe care și-a fondat PHE concluzia principală.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "10\n",
      "input_ids= Corneliu Vadim Tudor▁was▁born on▁November 28,▁1949, in▁Bucharest. He▁was a▁writer,▁politician and▁journalist.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "pred= Corneliu Vadim Tudor s-a născutscut pe 28 noiembrie 1949, la Bucuresti, scriitor scriitor, politician si jurnalist.</s>, al al al al al al al al al I I I I I I I I I I În În În În În În În\n",
      "label= <pad> Corneliu Vadim Tudor s-a nascut în 28 noiembrie 1949, în Bucuresti, era scriitor, politician și jurnalist.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "{'score': 7.704088373017681, 'counts': [1702, 1141, 807, 563], 'totals': [4631, 4543, 4455, 4367], 'precisions': [36.75232131289138, 25.115562403697997, 18.114478114478114, 12.892145637737578], 'bp': 0.35754159894027016, 'sys_len': 4631, 'ref_len': 9394}\n"
     ]
    }
   ],
   "source": [
    "#测试\n",
    "def test():\n",
    "    model.eval()\n",
    "\n",
    "    #数据加载器\n",
    "    loader_test = torch.utils.data.DataLoader(\n",
    "        dataset=dataset['test'],\n",
    "        batch_size=8,\n",
    "        collate_fn=collate_fn,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "\n",
    "    predictions = []\n",
    "    references = []\n",
    "    for i, data in enumerate(loader_test):\n",
    "        #计算\n",
    "        with torch.no_grad():\n",
    "            out = model(**data)\n",
    "\n",
    "        pred = tokenizer.batch_decode(out['logits'].argmax(dim=2))\n",
    "        label = tokenizer.batch_decode(data['decoder_input_ids'])\n",
    "        predictions.extend(pred)\n",
    "        references.extend(label)\n",
    "\n",
    "        if i % 2 == 0:\n",
    "            print(i)\n",
    "            input_ids = tokenizer.decode(data['input_ids'][0])\n",
    "\n",
    "            print('input_ids=', input_ids)\n",
    "            print('pred=', pred[0])\n",
    "            print('label=', label[0])\n",
    "\n",
    "        if i == 10:\n",
    "            break\n",
    "\n",
    "    references = [[j] for j in references]\n",
    "    metric_out = metric.compute(predictions=predictions, references=references)\n",
    "    print(metric_out)\n",
    "\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1375fcad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/pt39/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.4797824621200562 0.0 {'score': 9.120008577043292, 'counts': [221, 179, 149, 124], 'totals': [588, 580, 572, 564], 'precisions': [37.585034013605444, 30.862068965517242, 26.04895104895105, 21.98581560283688], 'bp': 0.31944937686506625, 'sys_len': 588, 'ref_len': 1259} 1.9992e-05\n",
      "50 1.293352723121643 0.0 {'score': 7.44164783389345, 'counts': [211, 153, 114, 87], 'totals': [578, 570, 562, 554], 'precisions': [36.50519031141869, 26.842105263157894, 20.284697508896798, 15.703971119133573], 'bp': 0.31483413242798336, 'sys_len': 578, 'ref_len': 1246} 1.9592e-05\n",
      "100 0.885346531867981 0.0033783783783783786 {'score': 6.751734803815611, 'counts': [201, 142, 104, 75], 'totals': [573, 565, 557, 549], 'precisions': [35.07853403141361, 25.13274336283186, 18.671454219030522, 13.66120218579235], 'bp': 0.31004753070168034, 'sys_len': 573, 'ref_len': 1244} 1.9192000000000002e-05\n",
      "150 0.8533743619918823 0.0 {'score': 13.686218267242388, 'counts': [171, 123, 94, 70], 'totals': [352, 344, 336, 328], 'precisions': [48.57954545454545, 35.75581395348837, 27.976190476190474, 21.341463414634145], 'bp': 0.4288745148193968, 'sys_len': 352, 'ref_len': 650} 1.8792000000000002e-05\n",
      "200 0.9598424434661865 0.006696428571428571 {'score': 11.613237056699216, 'counts': [189, 142, 111, 90], 'totals': [428, 420, 412, 404], 'precisions': [44.1588785046729, 33.80952380952381, 26.941747572815533, 22.277227722772277], 'bp': 0.3774568334075752, 'sys_len': 428, 'ref_len': 845} 1.8392e-05\n",
      "250 1.1830499172210693 0.0018656716417910447 {'score': 9.33844881232761, 'counts': [195, 140, 105, 79], 'totals': [505, 497, 489, 481], 'precisions': [38.613861386138616, 28.169014084507044, 21.47239263803681, 16.424116424116423], 'bp': 0.3752367871797581, 'sys_len': 505, 'ref_len': 1000} 1.7992e-05\n",
      "300 1.2433003187179565 0.005747126436781609 {'score': 7.525276183479098, 'counts': [220, 156, 125, 101], 'totals': [731, 723, 715, 707], 'precisions': [30.095759233926128, 21.57676348547718, 17.482517482517483, 14.285714285714286], 'bp': 0.37499291249083483, 'sys_len': 731, 'ref_len': 1448} 1.7592000000000004e-05\n",
      "350 1.0052417516708374 0.0 {'score': 16.42540458968082, 'counts': [152, 114, 92, 71], 'totals': [300, 292, 284, 276], 'precisions': [50.666666666666664, 39.04109589041096, 32.394366197183096, 25.72463768115942], 'bp': 0.4584060113052235, 'sys_len': 300, 'ref_len': 534} 1.7192e-05\n",
      "400 0.8489341735839844 0.003472222222222222 {'score': 25.45038314826629, 'counts': [165, 121, 98, 82], 'totals': [277, 269, 261, 253], 'precisions': [59.56678700361011, 44.98141263940521, 37.547892720306514, 32.41106719367589], 'bp': 0.5989151287945745, 'sys_len': 277, 'ref_len': 419} 1.6792e-05\n",
      "450 1.025385856628418 0.0045045045045045045 {'score': 6.321613087405688, 'counts': [277, 201, 153, 114], 'totals': [860, 852, 844, 836], 'precisions': [32.2093023255814, 23.591549295774648, 18.127962085308056, 13.636363636363637], 'bp': 0.3036557971960769, 'sys_len': 860, 'ref_len': 1885} 1.6392e-05\n",
      "500 0.5974541902542114 0.009615384615384616 {'score': 15.895866947214195, 'counts': [210, 162, 132, 106], 'totals': [419, 411, 403, 395], 'precisions': [50.11933174224344, 39.416058394160586, 32.754342431761785, 26.835443037974684], 'bp': 0.43789520451776154, 'sys_len': 419, 'ref_len': 765} 1.5992000000000002e-05\n",
      "550 0.6576382517814636 0.005434782608695652 {'score': 16.404655608983962, 'counts': [178, 135, 114, 96], 'totals': [368, 360, 352, 344], 'precisions': [48.369565217391305, 37.5, 32.38636363636363, 27.906976744186046], 'bp': 0.4584558407536559, 'sys_len': 368, 'ref_len': 655} 1.5592e-05\n",
      "600 0.9891085624694824 0.004807692307692308 {'score': 12.138898985258201, 'counts': [182, 124, 93, 67], 'totals': [391, 383, 375, 367], 'precisions': [46.547314578005114, 32.37597911227154, 24.8, 18.256130790190735], 'bp': 0.4223619702817352, 'sys_len': 391, 'ref_len': 728} 1.5192000000000003e-05\n",
      "650 0.6127076745033264 0.009615384615384616 {'score': 32.38544440960212, 'counts': [205, 163, 135, 111], 'totals': [310, 302, 294, 286], 'precisions': [66.12903225806451, 53.973509933774835, 45.91836734693877, 38.81118881118881], 'bp': 0.6448679721892344, 'sys_len': 310, 'ref_len': 446} 1.4792000000000002e-05\n",
      "700 0.8210155367851257 0.005434782608695652 {'score': 18.372122576609478, 'counts': [183, 139, 106, 81], 'totals': [356, 348, 340, 332], 'precisions': [51.40449438202247, 39.94252873563219, 31.176470588235293, 24.397590361445783], 'bp': 0.5197047682409304, 'sys_len': 356, 'ref_len': 589} 1.4392000000000002e-05\n",
      "750 0.8817370533943176 0.002551020408163265 {'score': 12.722478437317408, 'counts': [189, 132, 96, 68], 'totals': [406, 398, 390, 382], 'precisions': [46.55172413793103, 33.165829145728644, 24.615384615384617, 17.801047120418847], 'bp': 0.4436107094018198, 'sys_len': 406, 'ref_len': 736} 1.3992000000000001e-05\n",
      "800 0.6331095695495605 0.00625 {'score': 10.928230687356402, 'counts': [199, 143, 108, 82], 'totals': [459, 451, 443, 435], 'precisions': [43.35511982570806, 31.70731707317073, 24.37923250564334, 18.850574712643677], 'bp': 0.3876267378278905, 'sys_len': 459, 'ref_len': 894} 1.3592000000000001e-05\n",
      "850 0.7867997884750366 0.005 {'score': 8.328081352129253, 'counts': [225, 159, 114, 84], 'totals': [587, 579, 571, 563], 'precisions': [38.33049403747871, 27.46113989637306, 19.964973730297725, 14.920071047957371], 'bp': 0.3519405480154652, 'sys_len': 587, 'ref_len': 1200} 1.3192e-05\n",
      "900 0.694574773311615 0.008064516129032258 {'score': 15.35218989870982, 'counts': [230, 178, 146, 122], 'totals': [481, 473, 465, 457], 'precisions': [47.817047817047815, 37.63213530655391, 31.397849462365592, 26.695842450765863], 'bp': 0.4380755804601984, 'sys_len': 481, 'ref_len': 878} 1.2792e-05\n",
      "950 0.733869731426239 0.00641025641025641 {'score': 19.02747660424653, 'counts': [175, 131, 105, 86], 'totals': [327, 319, 311, 303], 'precisions': [53.51681957186544, 41.06583072100314, 33.762057877813504, 28.382838283828384], 'bp': 0.499479060623208, 'sys_len': 327, 'ref_len': 554} 1.2392000000000003e-05\n",
      "1000 0.8266855478286743 0.005067567567567568 {'score': 6.819899660461278, 'counts': [189, 139, 107, 85], 'totals': [559, 551, 543, 535], 'precisions': [33.810375670840784, 25.226860254083483, 19.70534069981584, 15.88785046728972], 'bp': 0.30001116172008474, 'sys_len': 559, 'ref_len': 1232} 1.1992000000000001e-05\n",
      "1050 0.9551225900650024 0.0031645569620253164 {'score': 4.813186864517226, 'counts': [174, 119, 89, 71], 'totals': [645, 637, 629, 621], 'precisions': [26.976744186046513, 18.681318681318682, 14.149443561208267, 11.43317230273752], 'bp': 0.28484390415198974, 'sys_len': 645, 'ref_len': 1455} 1.1592000000000002e-05\n",
      "1100 0.8034053444862366 0.0025 {'score': 10.073388836894791, 'counts': [154, 115, 85, 63], 'totals': [383, 375, 367, 359], 'precisions': [40.2088772845953, 30.666666666666668, 23.160762942779293, 17.54874651810585], 'bp': 0.37859835946871206, 'sys_len': 383, 'ref_len': 755} 1.1192e-05\n",
      "1150 0.5552195310592651 0.007211538461538462 {'score': 18.82198486205154, 'counts': [202, 163, 140, 123], 'totals': [394, 386, 378, 370], 'precisions': [51.26903553299493, 42.2279792746114, 37.03703703703704, 33.24324324324324], 'bp': 0.4658184137495495, 'sys_len': 394, 'ref_len': 695} 1.0792000000000001e-05\n",
      "1200 0.695573627948761 0.004518072289156626 {'score': 9.291763701551302, 'counts': [256, 191, 146, 111], 'totals': [640, 632, 624, 616], 'precisions': [40.0, 30.22151898734177, 23.397435897435898, 18.01948051948052], 'bp': 0.3477574586840902, 'sys_len': 640, 'ref_len': 1316} 1.0392e-05\n",
      "1250 0.819365918636322 0.008152173913043478 {'score': 13.632236028910249, 'counts': [171, 130, 101, 77], 'totals': [371, 363, 355, 347], 'precisions': [46.091644204851754, 35.81267217630854, 28.450704225352112, 22.19020172910663], 'bp': 0.42666674738059074, 'sys_len': 371, 'ref_len': 687} 9.992e-06\n",
      "1300 0.9107105731964111 0.006818181818181818 {'score': 14.549305368024523, 'counts': [190, 139, 108, 82], 'totals': [407, 399, 391, 383], 'precisions': [46.68304668304668, 34.83709273182957, 27.62148337595908, 21.409921671018278], 'bp': 0.4645970693408125, 'sys_len': 407, 'ref_len': 719} 9.592e-06\n",
      "1350 1.130139708518982 0.002232142857142857 {'score': 9.826719871623247, 'counts': [177, 124, 101, 81], 'totals': [410, 402, 394, 386], 'precisions': [43.170731707317074, 30.845771144278608, 25.634517766497463, 20.984455958549223], 'bp': 0.3377781859012509, 'sys_len': 410, 'ref_len': 855} 9.192000000000001e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1400 0.5198501944541931 0.004901960784313725 {'score': 10.956261133157897, 'counts': [168, 137, 117, 101], 'totals': [411, 403, 395, 387], 'precisions': [40.87591240875913, 33.99503722084367, 29.620253164556964, 26.098191214470283], 'bp': 0.34032341912768727, 'sys_len': 411, 'ref_len': 854} 8.792e-06\n",
      "1450 1.1050782203674316 0.0 {'score': 13.610779822702535, 'counts': [215, 156, 118, 87], 'totals': [472, 464, 456, 448], 'precisions': [45.55084745762712, 33.62068965517241, 25.87719298245614, 19.419642857142858], 'bp': 0.45953398785509414, 'sys_len': 472, 'ref_len': 839} 8.392e-06\n",
      "1500 0.7206818461418152 0.0055147058823529415 {'score': 11.547276583069706, 'counts': [219, 178, 151, 128], 'totals': [521, 513, 505, 497], 'precisions': [42.034548944337814, 34.69785575048733, 29.900990099009903, 25.75452716297787], 'bp': 0.35470517407082913, 'sys_len': 521, 'ref_len': 1061} 7.992e-06\n",
      "1550 0.9179471135139465 0.002976190476190476 {'score': 14.694674582896523, 'counts': [162, 117, 94, 76], 'totals': [331, 323, 315, 307], 'precisions': [48.94259818731118, 36.22291021671827, 29.841269841269842, 24.7557003257329], 'bp': 0.4343794326705179, 'sys_len': 331, 'ref_len': 607} 7.592e-06\n",
      "1600 1.0173852443695068 0.00423728813559322 {'score': 8.18403911648738, 'counts': [171, 113, 80, 54], 'totals': [458, 450, 442, 434], 'precisions': [37.33624454148472, 25.11111111111111, 18.099547511312217, 12.442396313364055], 'bp': 0.3817909406122358, 'sys_len': 458, 'ref_len': 899} 7.192e-06\n",
      "1650 0.8650031089782715 0.005597014925373134 {'score': 11.037164425091765, 'counts': [220, 164, 126, 96], 'totals': [526, 518, 510, 502], 'precisions': [41.82509505703422, 31.66023166023166, 24.705882352941178, 19.12350597609562], 'bp': 0.3924440825576447, 'sys_len': 526, 'ref_len': 1018} 6.792000000000001e-06\n",
      "1700 1.2027997970581055 0.002232142857142857 {'score': 9.460070036070388, 'counts': [166, 118, 90, 67], 'totals': [429, 421, 413, 405], 'precisions': [38.6946386946387, 28.028503562945367, 21.791767554479417, 16.54320987654321], 'bp': 0.3783150473009867, 'sys_len': 429, 'ref_len': 846} 6.392000000000001e-06\n",
      "1750 0.6639528274536133 0.006756756756756757 {'score': 11.28219029499677, 'counts': [235, 189, 159, 134], 'totals': [561, 553, 545, 537], 'precisions': [41.889483065953655, 34.177215189873415, 29.174311926605505, 24.953445065176908], 'bp': 0.3531020333600962, 'sys_len': 561, 'ref_len': 1145} 5.992e-06\n",
      "1800 1.0775151252746582 0.010964912280701754 {'score': 24.545363961668656, 'counts': [252, 185, 141, 107], 'totals': [445, 437, 429, 421], 'precisions': [56.62921348314607, 42.33409610983982, 32.86713286713287, 25.41567695961995], 'bp': 0.6524855457520217, 'sys_len': 445, 'ref_len': 635} 5.592000000000001e-06\n",
      "1850 0.804780125617981 0.0015432098765432098 {'score': 6.645815728454373, 'counts': [212, 160, 122, 93], 'totals': [600, 592, 584, 576], 'precisions': [35.333333333333336, 27.027027027027028, 20.89041095890411, 16.145833333333332], 'bp': 0.27896563782408473, 'sys_len': 600, 'ref_len': 1366} 5.1920000000000004e-06\n",
      "1900 0.7075636386871338 0.006944444444444444 {'score': 17.41158689229841, 'counts': [212, 171, 144, 124], 'totals': [432, 424, 416, 408], 'precisions': [49.074074074074076, 40.33018867924528, 34.61538461538461, 30.392156862745097], 'bp': 0.45836356826916247, 'sys_len': 432, 'ref_len': 769} 4.792000000000001e-06\n",
      "1950 0.8368552327156067 0.0021929824561403508 {'score': 8.739143266300326, 'counts': [186, 131, 95, 68], 'totals': [413, 405, 397, 389], 'precisions': [45.0363196125908, 32.34567901234568, 23.929471032745592, 17.480719794344473], 'bp': 0.3127886353708673, 'sys_len': 413, 'ref_len': 893} 4.3920000000000005e-06\n",
      "2000 0.9584644436836243 0.002777777777777778 {'score': 14.430251095756645, 'counts': [165, 130, 108, 88], 'totals': [355, 347, 339, 331], 'precisions': [46.478873239436616, 37.46397694524496, 31.858407079646017, 26.58610271903323], 'bp': 0.41408246223656014, 'sys_len': 355, 'ref_len': 668} 3.992e-06\n",
      "2050 0.6962317824363708 0.0 {'score': 7.36770153563903, 'counts': [186, 137, 109, 86], 'totals': [524, 516, 508, 500], 'precisions': [35.49618320610687, 26.550387596899224, 21.456692913385826, 17.2], 'bp': 0.30338638385452077, 'sys_len': 524, 'ref_len': 1149} 3.5920000000000005e-06\n",
      "2100 0.771067202091217 0.012295081967213115 {'score': 12.10464375249587, 'counts': [212, 152, 117, 89], 'totals': [487, 479, 471, 463], 'precisions': [43.53182751540041, 31.73277661795407, 24.840764331210192, 19.22246220302376], 'bp': 0.4247464681141713, 'sys_len': 487, 'ref_len': 904} 3.192e-06\n",
      "2150 0.5719201564788818 0.0 {'score': 5.69698294082286, 'counts': [195, 157, 130, 105], 'totals': [670, 662, 654, 646], 'precisions': [29.104477611940297, 23.716012084592144, 19.877675840978593, 16.25386996904025], 'bp': 0.2621585068568519, 'sys_len': 670, 'ref_len': 1567} 2.792e-06\n",
      "2200 0.8244491815567017 0.0037313432835820895 {'score': 9.597701250456165, 'counts': [196, 144, 114, 95], 'totals': [500, 492, 484, 476], 'precisions': [39.2, 29.26829268292683, 23.553719008264462, 19.95798319327731], 'bp': 0.35416229870357036, 'sys_len': 500, 'ref_len': 1019} 2.392e-06\n",
      "2250 0.8779654502868652 0.005319148936170213 {'score': 20.615544023744928, 'counts': [197, 148, 116, 91], 'totals': [362, 354, 346, 338], 'precisions': [54.41988950276243, 41.80790960451977, 33.52601156069364, 26.923076923076923], 'bp': 0.5445830589080478, 'sys_len': 362, 'ref_len': 582} 1.992e-06\n",
      "2300 0.9505125284194946 0.001488095238095238 {'score': 4.089062527705538, 'counts': [160, 114, 86, 67], 'totals': [626, 618, 610, 602], 'precisions': [25.559105431309906, 18.446601941747574, 14.098360655737705, 11.129568106312293], 'bp': 0.24793995226567583, 'sys_len': 626, 'ref_len': 1499} 1.5920000000000002e-06\n",
      "2350 1.0018764734268188 0.0024509803921568627 {'score': 7.216054898784825, 'counts': [281, 196, 145, 107], 'totals': [803, 795, 787, 779], 'precisions': [34.99377334993773, 24.654088050314467, 18.424396442185515, 13.735558408215661], 'bp': 0.33382587944334247, 'sys_len': 803, 'ref_len': 1684} 1.1920000000000002e-06\n",
      "2400 0.8622590899467468 0.002551020408163265 {'score': 9.48864330974091, 'counts': [156, 118, 94, 73], 'totals': [395, 387, 379, 371], 'precisions': [39.49367088607595, 30.49095607235142, 24.80211081794195, 19.67654986522911], 'bp': 0.3427047204344712, 'sys_len': 395, 'ref_len': 818} 7.920000000000001e-07\n",
      "2450 0.8322212100028992 0.00646551724137931 {'score': 12.492037786822925, 'counts': [202, 155, 125, 99], 'totals': [448, 440, 432, 424], 'precisions': [45.089285714285715, 35.22727272727273, 28.935185185185187, 23.349056603773583], 'bp': 0.38812471079490507, 'sys_len': 448, 'ref_len': 872} 3.92e-07\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "132b209a6980455a9b9b0540ba1a1911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a7f24c8c12c4beaaec115f62bae4b9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/423M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "from transformers.optimization import get_scheduler\n",
    "\n",
    "\n",
    "#训练\n",
    "def train():\n",
    "    optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "    scheduler = get_scheduler(name='linear',\n",
    "                              num_warmup_steps=0,\n",
    "                              num_training_steps=len(loader),\n",
    "                              optimizer=optimizer)\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    for i, data in enumerate(loader):\n",
    "        for k in data.keys():\n",
    "            data[k] = data[k].to(device)\n",
    "    \n",
    "        out = model(**data)\n",
    "        loss = out['loss']\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        model.zero_grad()\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            out = out['logits'].argmax(dim=2)\n",
    "            correct = (data['decoder_input_ids'] == out).sum().item()\n",
    "            total = data['decoder_input_ids'].shape[1] * 8\n",
    "            accuracy = correct / total\n",
    "            del correct\n",
    "            del total\n",
    "\n",
    "            predictions = []\n",
    "            references = []\n",
    "            for j in range(8):\n",
    "                pred = tokenizer.decode(out[j])\n",
    "                label = tokenizer.decode(data['decoder_input_ids'][j])\n",
    "                predictions.append(pred)\n",
    "                references.append([label])\n",
    "\n",
    "            metric_out = metric.compute(predictions=predictions,\n",
    "                                        references=references)\n",
    "\n",
    "            lr = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "\n",
    "            print(i, loss.item(), accuracy, metric_out, lr)\n",
    "\n",
    "    model.to('cpu')\n",
    "\n",
    "\n",
    "if push_to_hub:\n",
    "    train()\n",
    "    model.push_to_hub(repo_id=repo_id, use_auth_token=hub_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed397281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5518d5b505345a48e7fc40103a971d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/105 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec8ad099d6e04b9ab942f5010ad4bdc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/423M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Helsinki-NLP/opus-mt-en-ro were not used when initializing MarianModel: ['final_logits_bias']\n",
      "- This IS expected if you are initializing MarianModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MarianModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "input_ids= ▁After the public emotion▁passes,▁we▁will return to the▁reasons▁we▁have▁created▁this▁space, the▁freedom of▁movement that is not▁only for▁people but▁also for▁goods.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "pred= Dupăa ce emo emotia publica, ne vom intoarce la motivele pentru care am creat acesttiul,, libertatea libera de miscare care nu este numai pentru oameni, ci si pentru bunuri.</s> </s>,,,,,, - - - - - - - După După După După După După După După După După\n",
      "label= <pad> Dupa ce trece emotia publica, ne vom intoarce la motivele pentru care am creat spatiul acesta, aceasta libertate de miscare care nu e numai pentru oameni, ci și pentru bunuri.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "2\n",
      "input_ids= Am I▁bad for the▁industry?</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "pred= Sunt făcut atitudine negativă asupra industriei?</s>. sunt sunt Fac Fac Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt\n",
      "label= <pad> Am o influență proastă asupra industriei?</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "4\n",
      "input_ids= ▁That▁ended▁any▁ideas that Malmo▁had of▁coming▁back▁into the game, and▁only a superb stop by Wiland from▁point-blank▁range to▁deny David Luiz▁kept the final▁score▁down▁before▁substitute Ezequiel Lavezzi▁had a▁goal disallowed▁right▁at the▁death.</s>\n",
      "pred= Acest lucru a pus oriceele că pe la Malmo de va reveniintrașlibbra meciul final doar o super superb al lui Wiland de la distan, a ultim Luiz a fost scorul final înainte ca înlocui- în Ezequiel Lavzzi să aibă se fieze scopul gol chiar momentulle</s>\n",
      "label= <pad> Acest gol a eliminat speranța celor de la Malmo că vor reechilibra scorul și doar un stop superb al lui Wiland de la distanță pentru respingerea David Luiz a menținut scorul final înainte ca nou intratului Ezequiel Lavezzi să i se anuleze un gol în prelungiri.\n",
      "6\n",
      "input_ids= The BBC▁Music▁Awards▁which▁started▁last▁year▁seem to be the Brits by▁another name.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "pred= PreBC Music Awards, care anul trecut, par a fie britanicits cu alt alt nume.</s>, B B B B B B B B B B B B B B B B B B B B B B B B B B B Pre Pre Pre Pre Pre Pre Pre Pre Pre\n",
      "label= <pad> BBC Music Awards, lansate anul trecut, par să fie Brits sub un alt nume.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "8\n",
      "input_ids= You are a▁great▁power▁only▁if you▁have▁solutions.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "pred= Sunte sunt o, doar daca ai solu soluțiitii.</s>, esteti- - - - - Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte\n",
      "label= <pad> Dar esti mare putere doar daca ai și solutii.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "10\n",
      "input_ids= The▁company▁also▁said▁it▁plans to▁hire▁about 55,000▁seasonal▁workers for the▁holidays.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "pred= Compania a declarat de asemenea că inten să angajeze aproximativ vacan de 55 000 de lucrători sezonieri pentru sărbători delor.</s>,ulul pentru Pentru Compania Compania Compania Compania Compania Compania Compania Compania Compania Compania Compania Compania Compania Compania Compania Compania Compania Compania Compania Compania Compania Compania Compania Compania Compania Compania Compania Compania Compania Compania Compania Compania Compania Compania Compania Compania\n",
      "label= <pad> Compania a declarat de asemenea că intenționează să angajeze în jur de 55.000 de lucrători sezonieri pentru perioada sărbătorilor.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "{'score': 8.71658710506789, 'counts': [2000, 1378, 1008, 737], 'totals': [5299, 5211, 5123, 5035], 'precisions': [37.74297037176826, 26.444060640951832, 19.675971110677338, 14.637537239324727], 'bp': 0.3764474607075469, 'sys_len': 5299, 'ref_len': 10476}\n"
     ]
    }
   ],
   "source": [
    "#直接使用我训练好的模型\n",
    "model = Model.from_pretrained(repo_id)\n",
    "\n",
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
