{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a2bc9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#全局变量\n",
    "hub_token = open('/root/hub_token.txt').read().strip()\n",
    "repo_id = 'lansinuote/nlp.1.predict_last_word'\n",
    "push_to_hub = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff223689",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2TokenizerFast(name_or_path='distilgpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[24717, 649, 3200, 507, 422, 262, 21694, 4991], [3642, 1299, 645, 20868, 837, 691, 2248, 1850, 308, 3775]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "#加载编码器\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilgpt2', use_fast=True)\n",
    "\n",
    "print(tokenizer)\n",
    "\n",
    "#编码试算\n",
    "tokenizer.batch_encode_plus([\n",
    "    'hide new secretions from the parental units',\n",
    "    'contains no wit , only labored gags'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c10d4b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset glue (/root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b80aeccca848427ba61493747248d1d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-dfcf13f88e3dfa37.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-22588aea6bfeca67.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-77fd75f5f6f72f1c.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-d2e1fe5ad0a431f7.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-50dbea052a163dac.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-b59521550a1c8b8d.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-b1f2890101fd0309.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-4f95446eb74361d6.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-4ba6951069e5d245.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-4b4a2247273347cb.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-6729232cfa90d968.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-ec69373c8a7e0594.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-11a7f20e91bc0722_00000_of_00004.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-11a7f20e91bc0722_00001_of_00004.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-11a7f20e91bc0722_00002_of_00004.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-11a7f20e91bc0722_00003_of_00004.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-d4ab57cd9b372ac4_00000_of_00004.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-d4ab57cd9b372ac4_00001_of_00004.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-d4ab57cd9b372ac4_00002_of_00004.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-d4ab57cd9b372ac4_00003_of_00004.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-faf7d220a017eeed_00000_of_00004.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-faf7d220a017eeed_00001_of_00004.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-faf7d220a017eeed_00002_of_00004.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-faf7d220a017eeed_00003_of_00004.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-6db78647a6faba91.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-6d093ddfe87eb10b.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-f15c34c19a52c2ce.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-24c0ac570122f559.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-acd53424084fe9b7.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-116e420ad90fa123.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-8c4858d0c4c07737.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-ee1e092ebb679c75.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-1348d34756824232.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-5e4291ace3ff7a1b.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-9a3a21f3e7134b0a.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-f37e677285b39655.arrow\n",
      "Pushing split train to the Hub.\n",
      "Resuming upload of the dataset shards.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16d8ada1989b4345a735d2c61ab8a5e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing split validation to the Hub.\n",
      "Resuming upload of the dataset shards.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "861b8095c3ce4b00a0bb10de391e0f2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing split test to the Hub.\n",
      "Resuming upload of the dataset shards.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "849d254499444264962c48bdb6a63be2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration lansinuote--nlp.1.predict_last_word-4649910dfc3a98e4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset None/None to /root/.cache/huggingface/datasets/lansinuote___parquet/lansinuote--nlp.1.predict_last_word-4649910dfc3a98e4/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0997ccab810f44e8b06c62f4ba2f2bd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f38d77069ded4e0eb81c9e8e34685c37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/41.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f14d23af7b624c24b6a079623e3c0374",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/83.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1a6faa92a62461695c65cc3dce1036c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.89M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac923b2f07354b3f88c0dcea575446ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/848 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1730 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/39905 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/lansinuote___parquet/lansinuote--nlp.1.predict_last_word-4649910dfc3a98e4/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fc8c6e40fb840299b3a1dbd60856e50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(DatasetDict({\n",
       "     validation: Dataset({\n",
       "         features: ['input_ids', 'attention_mask', 'labels'],\n",
       "         num_rows: 848\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['input_ids', 'attention_mask', 'labels'],\n",
       "         num_rows: 1730\n",
       "     })\n",
       "     train: Dataset({\n",
       "         features: ['input_ids', 'attention_mask', 'labels'],\n",
       "         num_rows: 39905\n",
       "     })\n",
       " }),\n",
       " {'input_ids': [24717, 649, 3200, 507, 422, 262, 21694, 4991],\n",
       "  'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  'labels': [24717, 649, 3200, 507, 422, 262, 21694, 4991]})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "def get_dataset():\n",
    "    #加载数据\n",
    "    dataset = load_dataset(path='glue', name='sst2')\n",
    "\n",
    "    #分词,同时删除多余的字段\n",
    "    def f(data):\n",
    "        return tokenizer.batch_encode_plus(data['sentence'])\n",
    "\n",
    "    dataset = dataset.map(f,\n",
    "                          batched=True,\n",
    "                          batch_size=1000,\n",
    "                          num_proc=4,\n",
    "                          remove_columns=['sentence', 'idx', 'label'])\n",
    "\n",
    "    #过滤掉太短的句子\n",
    "    def f(data):\n",
    "        return [len(i) >= 8 for i in data['input_ids']]\n",
    "\n",
    "    dataset = dataset.filter(f, batched=True, batch_size=1000, num_proc=4)\n",
    "\n",
    "    #截断句子,同时整理成模型需要的格式\n",
    "    def f(data):\n",
    "        data['input_ids'] = [i[:8] for i in data['input_ids']]\n",
    "        data['attention_mask'] = [[1] * 8] * len(data['attention_mask'])\n",
    "        #在模型中处理了偏移量问题,这里保持输入输出一致即可\n",
    "        data['labels'] = data['input_ids'].copy()\n",
    "        return data\n",
    "\n",
    "    dataset = dataset.map(f, batched=True, batch_size=1000, num_proc=4)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "if push_to_hub:\n",
    "    dataset = get_dataset()\n",
    "    dataset.push_to_hub(repo_id=repo_id, token=hub_token)\n",
    "\n",
    "#直接使用我处理好的数据集\n",
    "dataset = load_dataset(path=repo_id)\n",
    "\n",
    "dataset, dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "405095b6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4988,\n",
       " {'input_ids': tensor([[  259,   257,  2565,   837,   326,   705,    82,   257],\n",
       "          [ 1169,  2646,   705,    82,  6218,   286, 15621,   290],\n",
       "          [   64,  1598,    12, 18834, 18560,   286,   281, 31146],\n",
       "          [   64,  3105,    12, 31462,  1644,    12,  1676,   771],\n",
       "          [  272,   512,   273,  1346, 38411,   605, 10997,   326],\n",
       "          [   86,   271,  8463,   318,  5827,   290, 34318, 47112],\n",
       "          [  271,   530,   286,   995, 22041,   705,    82,   749],\n",
       "          [   72,  2497,   340,   355,   257,  1862,  2933,   220]]),\n",
       "  'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1]]),\n",
       "  'labels': tensor([[  259,   257,  2565,   837,   326,   705,    82,   257],\n",
       "          [ 1169,  2646,   705,    82,  6218,   286, 15621,   290],\n",
       "          [   64,  1598,    12, 18834, 18560,   286,   281, 31146],\n",
       "          [   64,  3105,    12, 31462,  1644,    12,  1676,   771],\n",
       "          [  272,   512,   273,  1346, 38411,   605, 10997,   326],\n",
       "          [   86,   271,  8463,   318,  5827,   290, 34318, 47112],\n",
       "          [  271,   530,   286,   995, 22041,   705,    82,   749],\n",
       "          [   72,  2497,   340,   355,   257,  1862,  2933,   220]])})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers.data.data_collator import default_data_collator\n",
    "\n",
    "#数据加载器\n",
    "loader = torch.utils.data.DataLoader(\n",
    "    dataset=dataset['train'],\n",
    "    batch_size=8,\n",
    "    collate_fn=default_data_collator,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "for i, data in enumerate(loader):\n",
    "    break\n",
    "\n",
    "len(loader), data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f53f3c45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilgpt2 were not used when initializing GPT2Model: ['lm_head.weight']\n",
      "- This IS expected if you are initializing GPT2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12050.9952\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(5.6376, grad_fn=<NllLossBackward0>), torch.Size([8, 8, 50257]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, GPT2Model, PreTrainedModel, PretrainedConfig\n",
    "\n",
    "#加载模型\n",
    "#model = AutoModelForCausalLM.from_pretrained('distilgpt2')\n",
    "\n",
    "\n",
    "#定义下游任务模型\n",
    "class Model(PreTrainedModel):\n",
    "    config_class = PretrainedConfig\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.pretrained = GPT2Model.from_pretrained('distilgpt2')\n",
    "        self.fc = torch.nn.Linear(768, tokenizer.vocab_size, bias=False)\n",
    "\n",
    "        #加载预训练模型的参数\n",
    "        parameters = AutoModelForCausalLM.from_pretrained('distilgpt2')\n",
    "        self.fc.load_state_dict(parameters.lm_head.state_dict())\n",
    "\n",
    "        self.criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        logits = self.pretrained(input_ids=input_ids,\n",
    "                                 attention_mask=attention_mask)\n",
    "        logits = logits.last_hidden_state\n",
    "\n",
    "        logits = self.fc(logits)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            shift_logits = logits[:, :-1].reshape(-1, tokenizer.vocab_size)\n",
    "            shift_labels = labels[:, 1:].reshape(-1)\n",
    "\n",
    "            loss = self.criterion(shift_logits, shift_labels)\n",
    "\n",
    "        return {'loss': loss, 'logits': logits}\n",
    "\n",
    "\n",
    "model = Model(PretrainedConfig())\n",
    "\n",
    "#统计参数量\n",
    "print(sum(i.numel() for i in model.parameters()) / 10000)\n",
    "\n",
    "out = model(**data)\n",
    "\n",
    "out['loss'], out['logits'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6574726e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor([7297, 5667,  837,  303,  306,  705, 4661,  307])\n",
      "tensor([3807,  318,   13,  303,  290,   13, 4007,  307])\n",
      "10\n",
      "tensor([  389,   481,  4756,   991,   837, 10224, 24870,    82])\n",
      "tensor([ 547,   13, 1613,  314,   11,  290,  262,  464])\n",
      "20\n",
      "tensor([  286,   284,   318,   306,   257,   717,   262, 15444])\n",
      "tensor([286, 466, 318, 837, 257, 717, 257, 880])\n",
      "30\n",
      "tensor([27954,   837,   287,   345,   290,   345,   837,   764])\n",
      "tensor([262,  13, 287, 262, 290, 345, 290, 287])\n",
      "40\n",
      "tensor([16316, 42262,    12,  2984,   837,  2491,   764,   966])\n",
      "tensor([ 318, 2274, 5069,  351,   11, 2646,   13,  966])\n",
      "50\n",
      "tensor([4600, 3762,  837, 2700,  557,  262,  290, 2915])\n",
      "tensor([  198, 38393,   290,  8737, 32745,   262,    11,    12])\n",
      "0.19117647058823528\n",
      "dreary, highly annoying...\n",
      " ` \n",
      "\n",
      "\n",
      "an involving true story of a ch\n",
      "inese ubby\n",
      "\n",
      "no number of fantastic sets, extras\n",
      ",  and\n",
      "\n",
      "a work of astonishing delicacy and\n",
      " force  beauty\n",
      "\n",
      "credibility sinks into a m\n",
      "ire uddled\n",
      "\n",
      "... ( like ) channel surfing between\n",
      " the  the\n",
      "\n",
      "the film has a few cute ideas\n",
      " and ,\n",
      "\n",
      "there are touching moments in eto\n",
      "iles -\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#测试\n",
    "def test():\n",
    "    model.eval()\n",
    "\n",
    "    #数据加载器\n",
    "    loader_test = torch.utils.data.DataLoader(\n",
    "        dataset=dataset['test'],\n",
    "        batch_size=8,\n",
    "        collate_fn=default_data_collator,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(loader_test):\n",
    "        #只计算最后一个词的正确率,这里先把最后一个词取出来\n",
    "        label = data['input_ids'][:, -1].clone()\n",
    "\n",
    "        #从数据中抹除掉最后一个词,防止模型作弊\n",
    "        data['input_ids'][:, -1] = 0\n",
    "\n",
    "        #label就不需要了\n",
    "        data['labels'][:, :] = 0\n",
    "\n",
    "        #计算\n",
    "        with torch.no_grad():\n",
    "            out = model(**data)\n",
    "\n",
    "        #只计算最后一个词的正确率,因为有偏移量的关系,这里取的是倒数第二个词\n",
    "        out = out['logits'].argmax(dim=2)[:, -2]\n",
    "\n",
    "        correct += (label == out).sum().item()\n",
    "        total += 8\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(i)\n",
    "            print(label)\n",
    "            print(out)\n",
    "\n",
    "        if i == 50:\n",
    "            break\n",
    "\n",
    "    print(correct / total)\n",
    "\n",
    "    for i in range(8):\n",
    "        print(tokenizer.decode(data['input_ids'][i, :-1]))\n",
    "        print(tokenizer.decode(label[i]), tokenizer.decode(out[i]))\n",
    "        print()\n",
    "\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb0e6ed9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/pt39/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6.208362102508545 0.16071428571428573 1.999599037690457e-05\n",
      "50 5.238093376159668 0.21428571428571427 1.979550922213312e-05\n",
      "100 5.600107669830322 0.19642857142857142 1.959502806736167e-05\n",
      "150 5.695983409881592 0.17857142857142858 1.939454691259022e-05\n",
      "200 5.34975528717041 0.17857142857142858 1.9194065757818766e-05\n",
      "250 5.648352146148682 0.17857142857142858 1.8993584603047316e-05\n",
      "300 5.717629909515381 0.14285714285714285 1.8793103448275863e-05\n",
      "350 5.948981761932373 0.14285714285714285 1.8592622293504413e-05\n",
      "400 5.349982738494873 0.16071428571428573 1.839214113873296e-05\n",
      "450 5.168151378631592 0.21428571428571427 1.819165998396151e-05\n",
      "500 4.825538158416748 0.26785714285714285 1.7991178829190057e-05\n",
      "550 4.234778881072998 0.23214285714285715 1.7790697674418608e-05\n",
      "600 4.56860876083374 0.23214285714285715 1.7590216519647154e-05\n",
      "650 4.447201728820801 0.25 1.7389735364875705e-05\n",
      "700 4.872074604034424 0.25 1.718925421010425e-05\n",
      "750 4.521966457366943 0.32142857142857145 1.6988773055332802e-05\n",
      "800 5.1668596267700195 0.17857142857142858 1.678829190056135e-05\n",
      "850 5.061570644378662 0.16071428571428573 1.6587810745789896e-05\n",
      "900 5.910465240478516 0.17857142857142858 1.6387329591018446e-05\n",
      "950 4.944468975067139 0.25 1.6186848436246993e-05\n",
      "1000 5.741905689239502 0.125 1.5986367281475543e-05\n",
      "1050 4.6577019691467285 0.3392857142857143 1.578588612670409e-05\n",
      "1100 5.064526081085205 0.17857142857142858 1.558540497193264e-05\n",
      "1150 4.9257121086120605 0.26785714285714285 1.5384923817161187e-05\n",
      "1200 4.718228340148926 0.21428571428571427 1.5184442662389736e-05\n",
      "1250 5.353516578674316 0.23214285714285715 1.4983961507618286e-05\n",
      "1300 4.5461530685424805 0.25 1.4783480352846833e-05\n",
      "1350 4.319234371185303 0.26785714285714285 1.4582999198075383e-05\n",
      "1400 4.769099235534668 0.125 1.438251804330393e-05\n",
      "1450 4.36311149597168 0.32142857142857145 1.418203688853248e-05\n",
      "1500 5.186038494110107 0.17857142857142858 1.3981555733761027e-05\n",
      "1550 4.206788063049316 0.35714285714285715 1.3781074578989576e-05\n",
      "1600 4.660202503204346 0.25 1.3580593424218124e-05\n",
      "1650 4.456681728363037 0.2857142857142857 1.3380112269446673e-05\n",
      "1700 4.815407752990723 0.23214285714285715 1.3179631114675222e-05\n",
      "1750 4.729655742645264 0.21428571428571427 1.297914995990377e-05\n",
      "1800 4.679067134857178 0.25 1.2778668805132319e-05\n",
      "1850 4.702230930328369 0.16071428571428573 1.2578187650360867e-05\n",
      "1900 3.526611566543579 0.44642857142857145 1.2377706495589416e-05\n",
      "1950 5.37087869644165 0.23214285714285715 1.2177225340817965e-05\n",
      "2000 5.4608635902404785 0.21428571428571427 1.1976744186046511e-05\n",
      "2050 4.750507354736328 0.26785714285714285 1.1776263031275062e-05\n",
      "2100 5.510400295257568 0.21428571428571427 1.1575781876503609e-05\n",
      "2150 4.126431941986084 0.26785714285714285 1.1375300721732159e-05\n",
      "2200 4.346835136413574 0.30357142857142855 1.1174819566960706e-05\n",
      "2250 4.457627296447754 0.32142857142857145 1.0974338412189256e-05\n",
      "2300 4.9366631507873535 0.16071428571428573 1.0773857257417803e-05\n",
      "2350 4.31333589553833 0.25 1.0573376102646352e-05\n",
      "2400 4.04128360748291 0.30357142857142855 1.03728949478749e-05\n",
      "2450 4.2838134765625 0.32142857142857145 1.0172413793103449e-05\n",
      "2500 4.491302967071533 0.30357142857142855 9.971932638331997e-06\n",
      "2550 5.256004333496094 0.14285714285714285 9.771451483560546e-06\n",
      "2600 5.030401706695557 0.21428571428571427 9.570970328789094e-06\n",
      "2650 5.481937408447266 0.21428571428571427 9.370489174017643e-06\n",
      "2700 4.813111305236816 0.17857142857142858 9.170008019246192e-06\n",
      "2750 4.33260440826416 0.2857142857142857 8.96952686447474e-06\n",
      "2800 4.80324649810791 0.19642857142857142 8.769045709703289e-06\n",
      "2850 4.402346611022949 0.25 8.568564554931837e-06\n",
      "2900 4.8648600578308105 0.30357142857142855 8.368083400160386e-06\n",
      "2950 5.24068546295166 0.2857142857142857 8.167602245388933e-06\n",
      "3000 4.384514331817627 0.25 7.967121090617481e-06\n",
      "3050 4.483702182769775 0.21428571428571427 7.766639935846032e-06\n",
      "3100 5.168753147125244 0.26785714285714285 7.5661587810745795e-06\n",
      "3150 3.9833009243011475 0.30357142857142855 7.365677626303128e-06\n",
      "3200 4.930888652801514 0.21428571428571427 7.165196471531677e-06\n",
      "3250 4.499886989593506 0.26785714285714285 6.964715316760225e-06\n",
      "3300 4.194541931152344 0.30357142857142855 6.764234161988774e-06\n",
      "3350 3.771631956100464 0.3392857142857143 6.563753007217322e-06\n",
      "3400 5.038269996643066 0.21428571428571427 6.36327185244587e-06\n",
      "3450 4.800539493560791 0.21428571428571427 6.162790697674419e-06\n",
      "3500 4.816347599029541 0.21428571428571427 5.962309542902967e-06\n",
      "3550 4.618546009063721 0.21428571428571427 5.761828388131516e-06\n",
      "3600 4.147742748260498 0.35714285714285715 5.5613472333600645e-06\n",
      "3650 4.819380283355713 0.2857142857142857 5.360866078588613e-06\n",
      "3700 4.943516731262207 0.2857142857142857 5.1603849238171626e-06\n",
      "3750 5.1930766105651855 0.16071428571428573 4.95990376904571e-06\n",
      "3800 5.779540061950684 0.26785714285714285 4.759422614274258e-06\n",
      "3850 4.013110160827637 0.3392857142857143 4.558941459502807e-06\n",
      "3900 4.346842288970947 0.2857142857142857 4.358460304731355e-06\n",
      "3950 3.795379161834717 0.26785714285714285 4.157979149959905e-06\n",
      "4000 4.945191383361816 0.23214285714285715 3.957497995188452e-06\n",
      "4050 5.119272708892822 0.25 3.757016840417001e-06\n",
      "4100 4.141767978668213 0.30357142857142855 3.5565356856455496e-06\n",
      "4150 4.7401814460754395 0.26785714285714285 3.356054530874098e-06\n",
      "4200 4.736804008483887 0.17857142857142858 3.1555733761026463e-06\n",
      "4250 4.656920433044434 0.2857142857142857 2.955092221331195e-06\n",
      "4300 4.090821743011475 0.32142857142857145 2.7546110665597435e-06\n",
      "4350 4.762540340423584 0.2857142857142857 2.5541299117882925e-06\n",
      "4400 3.8685286045074463 0.3392857142857143 2.3536487570168407e-06\n",
      "4450 3.602297067642212 0.35714285714285715 2.153167602245389e-06\n",
      "4500 4.50552225112915 0.19642857142857142 1.952686447473938e-06\n",
      "4550 4.748764514923096 0.26785714285714285 1.752205292702486e-06\n",
      "4600 4.318875312805176 0.19642857142857142 1.5517241379310346e-06\n",
      "4650 4.140653133392334 0.35714285714285715 1.351242983159583e-06\n",
      "4700 4.7043280601501465 0.2857142857142857 1.1507618283881318e-06\n",
      "4750 4.45043420791626 0.25 9.502806736166801e-07\n",
      "4800 4.335289478302002 0.25 7.497995188452287e-07\n",
      "4850 4.226827621459961 0.3392857142857143 5.493183640737771e-07\n",
      "4900 4.966307640075684 0.21428571428571427 3.488372093023256e-07\n",
      "4950 4.646733283996582 0.26785714285714285 1.483560545308741e-07\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6a680eb675949e690170abba2d31e5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4759bcc1b3f4b278b5ed5d60fb17c5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/488M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "from transformers.optimization import get_scheduler\n",
    "\n",
    "\n",
    "#训练\n",
    "def train():\n",
    "    optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "    scheduler = get_scheduler(name='linear',\n",
    "                              num_warmup_steps=0,\n",
    "                              num_training_steps=len(loader),\n",
    "                              optimizer=optimizer)\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    for i, data in enumerate(loader):\n",
    "        for k in data.keys():\n",
    "            data[k] = data[k].to(device)\n",
    "\n",
    "        out = model(**data)\n",
    "        loss = out['loss']\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        model.zero_grad()\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            labels = data['labels'][:, 1:]\n",
    "            out = out['logits'].argmax(dim=2)[:, :-1]\n",
    "\n",
    "            correct = (labels == out).sum().item()\n",
    "            accuracy = correct / (8 * 7)\n",
    "\n",
    "            lr = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "\n",
    "            print(i, loss.item(), accuracy, lr)\n",
    "\n",
    "    model.to('cpu')\n",
    "\n",
    "\n",
    "if push_to_hub:\n",
    "    train()\n",
    "    model.push_to_hub(repo_id=repo_id, use_auth_token=hub_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9924f13e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34e44d04ecef447c9ec9c27ab6cd5eb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/488M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilgpt2 were not used when initializing GPT2Model: ['lm_head.weight']\n",
      "- This IS expected if you are initializing GPT2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor([1178,  257, 1200,   82, 1149,  611,  837, 2933])\n",
      "tensor([691, 257, 262,  82, 262, 287, 220, 262])\n",
      "10\n",
      "tensor([15366, 27235,   355,  2644,   379,  7058,    12,   468])\n",
      "tensor([ 518,   82,  355,  290,  262, 1267,   12,  705])\n",
      "20\n",
      "tensor([10735,   546,   837,  4035,  3923,  1645,  5924,   262])\n",
      "tensor([ 388,  257, 1165, 4035, 2646,  326,  407,  262])\n",
      "30\n",
      "tensor([ 3972,   837,   286,   475, 16316,   829,   705,   705])\n",
      "tensor([   83, 10997,   286,   475,   705,   293,   666,   705])\n",
      "40\n",
      "tensor([  357,  8531, 16631,  8886,   281, 26479,  8188,  2829])\n",
      "tensor([2431, 8258,  837, 8886,  299,  286, 8188, 1621])\n",
      "50\n",
      "tensor([ 5688, 26597,   465,   290,  1275,   257,  3101, 10997])\n",
      "tensor([  262, 26597,   290,   290,   318,   588,  3101, 10997])\n",
      "0.28921568627450983\n",
      "... the sum of the parts equals\n",
      " largely  the\n",
      "\n",
      "eastwood is an icon of mov\n",
      "iem iem\n",
      "\n",
      "guided more by intellect than heart,\n",
      " his  and\n",
      "\n",
      "this film is so slick, superficial\n",
      " and  and\n",
      "\n",
      "a mixed bag of a comedy that\n",
      " ca  is\n",
      "\n",
      "madonna still can't act\n",
      " a  like\n",
      "\n",
      "engagingly captures the madd\n",
      "ening ening\n",
      "\n",
      "a smart, sweet and playful romantic\n",
      " comedy  comedy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#直接使用我训练好的模型\n",
    "model = Model.from_pretrained(repo_id)\n",
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
